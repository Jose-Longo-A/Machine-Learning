{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#ml-jose-longo","title":"ML \u2022 Jos\u00e9 Longo","text":"<p>Este site re\u00fane meus estudos e entregas da disciplina Machine Learning (4\u00ba semestre \u2013 Ci\u00eancia de Dados, ESPM).  </p> <p>Aqui voc\u00ea encontra explora\u00e7\u00e3o de dados, modelos cl\u00e1ssicos (\u00c1rvore de Decis\u00e3o, KNN, K-Means), m\u00e9tricas e anota\u00e7\u00f5es.</p>"},{"location":"#redes-contato","title":"Redes &amp; contato","text":"<p> GitHub \u00b7  LinkedIn \u00b7  Portf\u00f3lio \u00b7  E-mail</p>"},{"location":"#o-que-tem-neste-site","title":"O que tem neste site","text":"<ul> <li>Exerc\u00edcios: implementa\u00e7\u00f5es guiadas dos principais algoritmos.  </li> <li>Projetos: aplica\u00e7\u00f5es um pouco maiores com an\u00e1lise e relat\u00f3rio final.  </li> <li>M\u00e9tricas: guia r\u00e1pido de acur\u00e1cia, precis\u00e3o, recall, F1, matriz de confus\u00e3o etc.</li> </ul>"},{"location":"#como-foi-feito","title":"Como foi feito","text":"<ul> <li>Documenta\u00e7\u00e3o com MkDocs Material </li> <li>\u00cdcones Font Awesome e Material Icons </li> <li>Build no GitHub Pages</li> </ul>"},{"location":"#ferramentas-utilizadas","title":"Ferramentas utilizadas","text":""},{"location":"indexHumberto/","title":"Template de Entrega","text":""},{"location":"indexHumberto/#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"indexHumberto/#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"indexHumberto/#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"indexHumberto/#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"indexHumberto/#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"indexHumberto/#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"indexHumberto/#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"Exercicios/arvore-de-decisao/main/","title":"\u00c1rvore de decis\u00e3o","text":""},{"location":"Exercicios/arvore-de-decisao/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>A \u00e1rvore de decis\u00e3o \u00e9 um algoritmo de aprendizado de m\u00e1quina utilizado para resolver problemas de classifica\u00e7\u00e3o e regress\u00e3o. Seu funcionamento se baseia em uma estrutura hier\u00e1rquica de n\u00f3s, onde cada divis\u00e3o (ramo) representa uma condi\u00e7\u00e3o aplicada sobre uma vari\u00e1vel, conduzindo a diferentes caminhos at\u00e9 chegar a um resultado final (folha). Essa t\u00e9cnica se destaca por sua simplicidade e interpretabilidade, permitindo compreender de forma clara quais fatores influenciam nas decis\u00f5es do modelo. Al\u00e9m disso, as \u00e1rvores de decis\u00e3o conseguem lidar com vari\u00e1veis num\u00e9ricas e categ\u00f3ricas, sendo uma ferramenta vers\u00e1til para an\u00e1lise e previs\u00e3o em diferentes contextos.</p>"},{"location":"Exercicios/arvore-de-decisao/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":""},{"location":"Exercicios/arvore-de-decisao/main/#o-dataset","title":"O Dataset","text":"<p>Para esse projeto foi utilizada o Dataset Fitness Classification Dataset. Essa Base de dados posu\u00ed 2.000 linhas e 11 colunas. A vari\u00e1vel dependente que ser\u00e1 usada como objeto de classifica\u00e7\u00e3o \u00e9 a is_fit, ela indica se a pessoa \u00e9 fit (1) ou n\u00e3o fit (0).</p>"},{"location":"Exercicios/arvore-de-decisao/main/#analise-dos-dados","title":"An\u00e1lise dos dados","text":"Ageheight_cmweight_kgheart_rateblood_pressureSleep_HoursNutrition_qualityActivity_indexsmokesgenderis_fit <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: idade em anos.</p> <p>Para que serve: pode relacionar-se com h\u00e1bitos e condi\u00e7\u00e3o f\u00edsica.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; s\u00f3 checar faixas implaus\u00edveis (n\u00e3o observei no geral).</p> 2025-10-28T15:18:48.264193 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: altura em cent\u00edmetros.</p> <p>Para que serve: isoladamente costuma ter pouco poder; combinada ao peso forma o BMI.</p> <p>A\u00e7\u00e3o necess\u00e1ria: checar valores muito fora do plaus\u00edvel. Sugest\u00e3o: considerar substituir altura e peso por bmi(\u00cdndice de Massa Corporal).</p> 2025-10-28T15:18:48.336544 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: peso em quilogramas.</p> <p>Para que serve: junto com a altura permite calcular BMI = peso(kg) / (altura(m))\u00b2, que costuma ser mais informativo para a \u00e1rvore.</p> <p>A\u00e7\u00e3o necess\u00e1ria: manter como num\u00e9rica ou criar bmi e remover height_cm/weight_kg das features (deixando s\u00f3 o bmi).</p> 2025-10-28T15:18:48.424330 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: frequ\u00eancia card\u00edaca (bpm).</p> <p>Para que serve: indicador de condicionamento cardiovascular; pode ajudar na separa\u00e7\u00e3o das classes.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; apenas conferir plausibilidade de valores extremos.</p> 2025-10-28T15:18:48.479968 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: medida sint\u00e9tica de press\u00e3o arterial fornecida pelo dataset.</p> <p>Para que serve: sinal de sa\u00fade geral que pode complementar a predi\u00e7\u00e3o.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; s\u00f3 verificar extremos muito fora do usual.</p> 2025-10-28T15:18:48.569343 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: horas de sono por dia.</p> <p>Para que serve: h\u00e1bito de descanso; costuma ter correla\u00e7\u00e3o com \u201cestar fit\u201d.</p> <p>A\u00e7\u00e3o necess\u00e1ria: possui valores ausentes (160 valores); imputar com a mediana.</p> 2025-10-28T15:18:48.643036 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua (escala)</p> <p>O que \u00e9: qualidade da nutri\u00e7\u00e3o (escala cont\u00ednua, ex.: 0\u201310).</p> <p>Para que serve: proxy de alimenta\u00e7\u00e3o saud\u00e1vel; geralmente relevante.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma; manter como num\u00e9rica (s\u00f3 garantir faixa v\u00e1lida).</p> 2025-10-28T15:18:48.720499 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua (escala)</p> <p>O que \u00e9: n\u00edvel de atividade f\u00edsica (escala cont\u00ednua, ex.: 0\u201310).</p> <p>Para que serve: costuma ser uma das vari\u00e1veis mais importantes para is_fit.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma; manter como num\u00e9rica (garantir faixa v\u00e1lida).</p> 2025-10-28T15:18:48.794928 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria</p> <p>O que \u00e9: status de tabagismo (sim/n\u00e3o).</p> <p>Para que serve: fator de estilo de vida; pode ajudar a separar perfis.</p> <p>A\u00e7\u00e3o necess\u00e1ria: tipos mistos no bruto (\u201cyes/no\u201d e \u201c1/0\u201d). Padronizar para bin\u00e1rio num\u00e9rico (no\u21920, yes\u21921) e converter para int.</p> 2025-10-28T15:18:48.881866 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria</p> <p>O que \u00e9: g\u00eanero (F/M).</p> <p>Para que serve: poss\u00edvel moderador de outros efeitos; em geral fraco sozinho.</p> <p>A\u00e7\u00e3o necess\u00e1ria: codificar para num\u00e9rico (F\u21920, M\u21921) e converter para int.</p> 2025-10-28T15:18:48.910553 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria (target)</p> <p>O que \u00e9: r\u00f3tulo de condi\u00e7\u00e3o f\u00edsica (1 = fit, 0 = n\u00e3o fit).</p> <p>Para que serve: vari\u00e1vel dependente a ser prevista.</p> <p>A\u00e7\u00e3o necess\u00e1ria: checar balanceamento das classes.</p> 2025-10-28T15:18:48.965727 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"Exercicios/arvore-de-decisao/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Nesta etapa tratei e preparei os dados para treinar a \u00c1rvore de Decis\u00e3o. Antes do tratamento, a base apresentava valores ausentes em sleep_hours, tipos mistos em smokes (valores como yes/no e 0/1 ao mesmo tempo) e vari\u00e1veis categ\u00f3ricas em texto (gender com F/M). Abaixo, o que foi feito:</p> <p>\u2022 Padroniza\u00e7\u00e3o de categ\u00f3ricas</p> <ul> <li> <p>smokes: normalizei r\u00f3tulos e converti para bin\u00e1rio num\u00e9rico (no\u21920, yes\u21921, cobrindo tamb\u00e9m 0/1 em string).</p> </li> <li> <p>gender: converti F\u21920 e M\u21921.</p> </li> </ul> <p>\u2022 Valores ausentes</p> <ul> <li>sleep_hours: converti para num\u00e9rico e imputei a mediana.</li> </ul> <p>\u2022 Tipos e consist\u00eancia</p> <ul> <li>Garanti que as vari\u00e1veis cont\u00ednuas ficaram em formato num\u00e9rico, sem strings residuais/espac\u0327os.</li> </ul> <p>\u2022 Cria\u00e7\u00e3o de nova vari\u00e1vel</p> <ul> <li>Criei a vari\u00e1vel BMI (peso(kg) / altura(m)\u00b2) para avaliar seu impacto. Na explora\u00e7\u00e3o, mantenho height_cm e weight_kg para refer\u00eancia; na modelagem, comparo dois cen\u00e1rios: (A) sem BMI (altura + peso) e (B) com apenas BMI, evitando usar os tr\u00eas juntos no mesmo modelo para n\u00e3o introduzir redund\u00e2ncia.</li> </ul> Base originalTratamentoBase Tratada age height_cm weight_kg heart_rate blood_pressure sleep_hours nutrition_quality activity_index smokes gender is_fit 43 193 80 62.4 109.9 8.9 4.17 2.08 yes F 0 64 199 104 72.7 136.6 6.4 1.7 3.47 0 F 0 66 190 65 73.5 116.2 8.3 2.5 1.67 0 M 0 55 175 45 87.5 128.2 8.5 5.52 4.15 no F 0 29 174 82 77.1 124 7.4 2.78 1.97 no M 1 69 171 74 72 111.1 7.7 6.77 3.09 yes F 0 42 167 103 85.7 138.2 9.4 7.25 4.18 yes F 1 20 181 56 70.3 115.6 6.8 1.22 2.55 1 F 0 75 165 72 89.3 100.5 9.3 7.15 1.82 yes M 1 64 184 53 71.6 142.1 7.6 4.11 3.47 yes M 0 43 156 117 60.7 113.2 5.6 3.91 2.55 yes F 0 78 178 111 83.2 122 7.8 9.29 2.36 no F 0 68 197 59 75.2 97.9 7.9 1.46 2.28 yes M 0 73 173 75 65.7 149.7 9.6 2.37 3.24 0 F 0 66 174 69 74.1 121.2 5.3 6.8 4.98 no F 1 <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\ndf[\"sleep_hours\"] = df[\"sleep_hours\"].fillna(df[\"sleep_hours\"].median())\n\ndf[\"smokes\"] = (\n    df[\"smokes\"].astype(str).str.strip().str.lower()\n      .map({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0})\n).astype(int)\n\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m**2)\ndf[\"bmi\"] = bmi.replace([float(\"inf\"), float(\"-inf\")], pd.NA).fillna(bmi.median())\n\nprint(df.sample(n=15).to_markdown(index=False))\n</code></pre> age height_cm weight_kg heart_rate blood_pressure sleep_hours nutrition_quality activity_index smokes gender is_fit bmi 24 169 49 63.1 117.9 10.6 4.31 2.72 0 1 0 17.1563 46 178 97 70.4 122.8 8.7 6.38 1.72 0 0 0 30.6148 77 151 62 59.7 157.7 8.1 1.09 3.84 0 1 0 27.1918 47 163 72 58.9 120.3 7 0.04 4.98 1 1 0 27.0993 51 184 102 75.5 114.3 8 1 2.62 1 1 0 30.1276 41 183 60 70.9 132.2 4.3 0.99 2.16 1 1 0 17.9163 20 196 75 56.8 113.1 9.2 6.83 4.94 0 0 1 19.5231 67 159 92 56.1 119 8.6 2.09 3.81 0 1 1 36.391 74 164 79 56.9 101.9 10.4 0.28 3.86 0 1 1 29.3724 52 161 59 75 116.1 7.5 7.93 3.77 1 0 0 22.7615 57 157 94 75.6 116.7 10.4 5.13 3.38 0 0 1 38.1354 60 191 107 79.3 98.2 7.1 6.54 2.7 1 0 0 29.3303 20 166 81 65.1 146.9 5.8 3.53 3.46 0 0 1 29.3947 66 186 53 68.6 121.8 6.3 7.63 3.66 0 0 0 15.3197 50 161 109 72.6 136.3 7.7 5.8 1.76 1 0 0 42.0508"},{"location":"Exercicios/arvore-de-decisao/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>Nesta etapa separei o conjunto em treino (70%) e teste (30%) para avaliar a \u00e1rvore em dados n\u00e3o vistos. Usei random_state=42 para reprodutibilidade e stratify=y para manter a propor\u00e7\u00e3o de is_fit em treino e teste. Antes do split, finalizei o pr\u00e9-processamento (imputa\u00e7\u00e3o da mediana em sleep_hours, padroniza\u00e7\u00e3o de smokes para 0/1 e de gender para 0/1). </p> <p>Nota: em um pipeline mais r\u00edgido, a imputa\u00e7\u00e3o/codifica\u00e7\u00e3o seria ajustada no treino e aplicada no teste para evitar vazamento; aqui mantive a simplicidade do material.</p> Cen\u00e1rio ACen\u00e1rio B <p>Features: age, height_cm, weight_kg, heart_rate, blood_pressure, sleep_hours, nutrition_quality, activity_index, smokes, gender.</p> <p>Objetivo: servir de refer\u00eancia para comparar com a vers\u00e3o engenheirada. </p> <p>Mesma configura\u00e7\u00e3o de split (70/30, random_state=42, stratify=y).</p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\nplt.figure(figsize=(12, 10))\n\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\nlabel_encoder = LabelEncoder()\n\n#Tratamento de dados nulos e categ\u00f3ricos\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\ndf[\"sleep_hours\"] = df[\"sleep_hours\"].fillna(df[\"sleep_hours\"].median())\n\ndf[\"smokes\"] = (\n    df[\"smokes\"].astype(str).str.strip().str.lower()\n      .map({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0})\n).astype(int)\n\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\n# Carregar o conjunto de dados\nx = df[['age', 'height_cm', 'weight_kg', 'heart_rate', 'blood_pressure',\n       'sleep_hours', 'nutrition_quality', 'activity_index', 'smokes',\n       'gender']]\ny = df['is_fit']\n\n# Dividir os dados em conjuntos de treinamento e teste\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n</code></pre> <p>Engenharia: criei bmi = peso(kg)/altura(m)\u00b2 (c\u00e1lculo linha a linha, sem vazamento). Features: age, bmi, heart_rate, blood_pressure, sleep_hours, nutrition_quality, activity_index, smokes, gender.</p> <p>Objetivo: avaliar o impacto do BMI na acur\u00e1cia e na simplicidade da \u00e1rvore. Mantive height_cm e weight_kg na base tratada para transpar\u00eancia, mas retirei essas colunas apenas na sele\u00e7\u00e3o das features do Cen\u00e1rio B para evitar redund\u00e2ncia com o bmi.</p> <p>Compara\u00e7\u00e3o justa: ambos os cen\u00e1rios usam o mesmo split (70/30, random_state=42, stratify=y).</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\nplt.figure(figsize=(12, 10))\n\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\nlabel_encoder = LabelEncoder()\n\n# Tratamento de dados nulos e categ\u00f3ricos\ndf[\"sleep_hours\"] = pd.to_numeric(df[\"sleep_hours\"], errors=\"coerce\").fillna(df[\"sleep_hours\"].median())\n\ndf[\"smokes\"] = (\n    df[\"smokes\"].astype(str).str.strip().str.lower()\n      .map({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0})\n).astype(int)\n\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\n# BMI = peso(kg) / (altura(m))^2\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m**2)\ndf[\"bmi\"] = bmi.replace([np.inf, -np.inf], np.nan).fillna(bmi.median())\n\n# Features (com BMI, substitui altura e peso)\nx = df[['age', 'bmi', 'heart_rate', 'blood_pressure',\n        'sleep_hours', 'nutrition_quality', 'activity_index', 'smokes', 'gender']]\ny = df['is_fit']\n\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n</code></pre>"},{"location":"Exercicios/arvore-de-decisao/main/#primeiro-treinamento-do-modelo","title":"Primeiro Treinamento do Modelo","text":"\u00c1rvorecode <p>Acur\u00e1cia da valida\u00e7\u00e3o: 0.6883 Import\u00e2ncia das Features: Feature Import\u00e2ncia activity_index 0.232233 nutrition_quality 0.175132 bmi 0.123847 age 0.115741 smokes 0.109310 sleep_hours 0.086928 heart_rate 0.082296 blood_pressure 0.064948 gender 0.009565 \u00c1rvore de Decis\u00e3o (SVG): 2025-10-28T15:18:51.180292 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\nplt.figure(figsize=(12, 10))\n\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\nlabel_encoder = LabelEncoder()\n\ndf[\"sleep_hours\"] = pd.to_numeric(df[\"sleep_hours\"], errors=\"coerce\").fillna(df[\"sleep_hours\"].median())\ndf[\"smokes\"] = (df[\"smokes\"].astype(str).str.strip().str.lower().map({\"yes\":1,\"no\":0,\"1\":1,\"0\":0})).astype(int)\ndf[\"gender\"] = df[\"gender\"].replace({\"F\":0,\"M\":1}).astype(int)\n\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m**2)\ndf[\"bmi\"] = bmi.replace([np.inf, -np.inf], np.nan).fillna(bmi.median())\n\nx = df[['age','bmi','heart_rate','blood_pressure',\n        'sleep_hours','nutrition_quality','activity_index',\n        'smokes','gender']]\ny = df['is_fit'].astype(int)\n\nx_train, x_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.3, random_state=42, stratify=y\n)\n\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(x_train, y_train)\n\nacc = accuracy_score(y_test, classifier.predict(x_test))\nprint(f\"&lt;b&gt;Acur\u00e1cia da valida\u00e7\u00e3o:&lt;/b&gt; {acc:.4f}&lt;br&gt;\")\n\nimp = pd.Series(classifier.feature_importances_, index=x.columns)\nimp_df = pd.DataFrame({\"Feature\": imp.index, \"Import\u00e2ncia\": imp.values}).sort_values(\"Import\u00e2ncia\", ascending=False)\nprint(\"&lt;br&gt;&lt;b&gt;Import\u00e2ncia das Features:&lt;/b&gt;\")\nprint(imp_df.to_html(index=False))\n\ntree.plot_tree(classifier, max_depth=4, fontsize=10,\n               feature_names=x.columns, class_names=[\"N\u00e3o Fit\",\"Fit\"], filled=True)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", bbox_inches=\"tight\", transparent=True)\nprint(\"&lt;br&gt;&lt;b&gt;\u00c1rvore de Decis\u00e3o (SVG):&lt;/b&gt;&lt;br&gt;\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"Exercicios/arvore-de-decisao/main/#avaliacao-do-primeiro-modelo","title":"Avalia\u00e7\u00e3o do primeiro modelo","text":"<p>O modelo com todas as vari\u00e1veis atingiu 68,83% de precis\u00e3o. As que mais pesaram foram activity_index (23,2%) e nutrition_quality (17,5%), seguidas por bmi (12,4%), age (11,6%) e smokes (10,9%). J\u00e1 sleep_hours (8,7%), heart_rate (8,2%), blood_pressure (6,5%) e, principalmente, gender (1,0%) tiveram impacto baixo. Em resumo: o sinal principal vem de atividade f\u00edsica e qualidade da alimenta\u00e7\u00e3o, com um complemento do BMI e idade.</p>"},{"location":"Exercicios/arvore-de-decisao/main/#segundo-treinamento-do-modelo","title":"Segundo Treinamento do Modelo","text":"\u00c1rvorecode <p>Acur\u00e1cia da valida\u00e7\u00e3o: 0.6900 Import\u00e2ncia das Features: Feature Import\u00e2ncia activity_index 0.259955 nutrition_quality 0.211840 bmi 0.196297 age 0.134762 smokes 0.109310 sleep_hours 0.087836 \u00c1rvore de Decis\u00e3o (SVG): 2025-10-28T15:18:52.297466 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\nplt.figure(figsize=(12, 10))\n\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\nlabel_encoder = LabelEncoder()\n\ndf[\"sleep_hours\"] = pd.to_numeric(df[\"sleep_hours\"], errors=\"coerce\").fillna(df[\"sleep_hours\"].median())\ndf[\"smokes\"] = (df[\"smokes\"].astype(str).str.strip().str.lower().map({\"yes\":1,\"no\":0,\"1\":1,\"0\":0})).astype(int)\ndf[\"gender\"] = df[\"gender\"].replace({\"F\":0,\"M\":1}).astype(int)\n\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m**2)\ndf[\"bmi\"] = bmi.replace([np.inf, -np.inf], np.nan).fillna(bmi.median())\n\nx = df[['activity_index', 'nutrition_quality', 'bmi', \n        'age', 'sleep_hours', 'smokes']]\ny = df['is_fit'].astype(int)\n\nx_train, x_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.3, random_state=42, stratify=y\n)\n\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(x_train, y_train)\n\nacc = accuracy_score(y_test, classifier.predict(x_test))\nprint(f\"&lt;b&gt;Acur\u00e1cia da valida\u00e7\u00e3o:&lt;/b&gt; {acc:.4f}&lt;br&gt;\")\n\nimp = pd.Series(classifier.feature_importances_, index=x.columns)\nimp_df = pd.DataFrame({\"Feature\": imp.index, \"Import\u00e2ncia\": imp.values}).sort_values(\"Import\u00e2ncia\", ascending=False)\nprint(\"&lt;br&gt;&lt;b&gt;Import\u00e2ncia das Features:&lt;/b&gt;\")\nprint(imp_df.to_html(index=False))\n\ntree.plot_tree(classifier, max_depth=4, fontsize=10,\n               feature_names=x.columns, class_names=[\"N\u00e3o Fit\",\"Fit\"], filled=True)\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", bbox_inches=\"tight\", transparent=True)\nprint(\"&lt;br&gt;&lt;b&gt;\u00c1rvore de Decis\u00e3o (SVG):&lt;/b&gt;&lt;br&gt;\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"Exercicios/arvore-de-decisao/main/#avaliacao-do-segundo-modelo","title":"Avalia\u00e7\u00e3o do segundo modelo","text":"<p>Ao remover as vari\u00e1veis mais fracas (gender, blood_pressure e heart_rate) e manter apenas as mais relevantes, a precis\u00e3o subiu levemente para 69,00% (+0,17 p.p.). A import\u00e2ncia ficou ainda mais concentrada em activity_index (26,0%), nutrition_quality (21,2%) e bmi (19,6%), com age (13,5%), smokes (10,9%) e sleep_hours (8,8%) completando o conjunto.</p> <p>Conclus\u00e3o desta compara\u00e7\u00e3o: tirar as vari\u00e1veis com pouco sinal reduz ru\u00eddo e deixa a \u00e1rvore mais simples, mantendo (ou melhorando) a precis\u00e3o. Para a avalia\u00e7\u00e3o final, faz sentido seguir com o modelo compacto com BMI.</p>"},{"location":"Exercicios/arvore-de-decisao/main/#relatorio-final","title":"Relat\u00f3rio Final","text":"<p>\u00c1rvores de decis\u00e3o n\u00e3o pedem normaliza\u00e7\u00e3o, ent\u00e3o o que realmente ajudou aqui foi tratar a base (padronizar smokes/gender, imputar sleep_hours) e criar o bmi. Comparei dois modelos e fiquei com o compacto com BMI: \u00e9 mais simples e bateu ~69,00% de precis\u00e3o (contra 68,83% do completo). As vari\u00e1veis que mais fizeram diferen\u00e7a foram activity_index, nutrition_quality e bmi; idade, sono e tabagismo somaram um pouco. Mantive split 70/30 estratificado \u2014 reduzir o teste n\u00e3o melhora o modelo e ainda piora a avalia\u00e7\u00e3o. Resumo: dados limpos + bons atributos valem mais do que mexer em escala quando o modelo \u00e9 uma \u00e1rvore.</p>"},{"location":"Exercicios/k-means/main/","title":"K-Means","text":""},{"location":"Exercicios/k-means/main/#introducao-ao-k-means","title":"Introdu\u00e7\u00e3o ao K-Means","text":"<p>O algoritmo K-Means foi aplicado com o objetivo de identificar padr\u00f5es e agrupar os indiv\u00edduos em clusters com caracter\u00edsticas semelhantes relacionadas \u00e0 sa\u00fade e ao condicionamento f\u00edsico. Diferente dos m\u00e9todos supervisionados, como a \u00e1rvore de decis\u00e3o e o KNN, o K-Means \u00e9 um algoritmo de aprendizado n\u00e3o supervisionado, que organiza os dados em grupos de acordo com a proximidade entre seus atributos, sem utilizar diretamente a vari\u00e1vel-alvo is_fit como guia. Dessa forma, \u00e9 poss\u00edvel verificar se os agrupamentos formados refletem, ao menos parcialmente, a divis\u00e3o entre pessoas classificadas como \u201cfit\u201d e \u201cn\u00e3o fit\u201d, oferecendo uma perspectiva complementar sobre como os h\u00e1bitos e indicadores de sa\u00fade se distribuem na base.</p>"},{"location":"Exercicios/k-means/main/#descricao-sobre-o-banco","title":"Descri\u00e7\u00e3o sobre o banco","text":"<p>Para mais informa\u00e7\u00f5es, cheque a p\u00e1gina sobre \u00c1rvore de decis\u00e3o, aqui tem toda a explica\u00e7\u00e3o necess\u00e1ria para compreender as vari\u00e1veis e as outras coisas.</p>"},{"location":"Exercicios/k-means/main/#analise-dos-dados","title":"An\u00e1lise dos dados","text":"Ageheight_cmweight_kgheart_rateblood_pressureSleep_HoursNutrition_qualityActivity_indexsmokesgenderis_fit <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: idade em anos.</p> <p>Para que serve: pode relacionar-se com h\u00e1bitos e condi\u00e7\u00e3o f\u00edsica.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; s\u00f3 checar faixas implaus\u00edveis (n\u00e3o observei no geral).</p> 2025-10-28T15:18:52.984851 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: altura em cent\u00edmetros.</p> <p>Para que serve: isoladamente costuma ter pouco poder; combinada ao peso forma o BMI.</p> <p>A\u00e7\u00e3o necess\u00e1ria: checar valores muito fora do plaus\u00edvel. Sugest\u00e3o: considerar substituir altura e peso por bmi(\u00cdndice de Massa Corporal).</p> 2025-10-28T15:18:53.054116 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: peso em quilogramas.</p> <p>Para que serve: junto com a altura permite calcular BMI = peso(kg) / (altura(m))\u00b2, que costuma ser mais informativo para a \u00e1rvore.</p> <p>A\u00e7\u00e3o necess\u00e1ria: manter como num\u00e9rica ou criar bmi e remover height_cm/weight_kg das features (deixando s\u00f3 o bmi).</p> 2025-10-28T15:18:53.141428 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: frequ\u00eancia card\u00edaca (bpm).</p> <p>Para que serve: indicador de condicionamento cardiovascular; pode ajudar na separa\u00e7\u00e3o das classes.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; apenas conferir plausibilidade de valores extremos.</p> 2025-10-28T15:18:53.196488 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: medida sint\u00e9tica de press\u00e3o arterial fornecida pelo dataset.</p> <p>Para que serve: sinal de sa\u00fade geral que pode complementar a predi\u00e7\u00e3o.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; s\u00f3 verificar extremos muito fora do usual.</p> 2025-10-28T15:18:53.282866 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: horas de sono por dia.</p> <p>Para que serve: h\u00e1bito de descanso; costuma ter correla\u00e7\u00e3o com \u201cestar fit\u201d.</p> <p>A\u00e7\u00e3o necess\u00e1ria: possui valores ausentes (160 valores); imputar com a mediana.</p> 2025-10-28T15:18:53.356182 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua (escala)</p> <p>O que \u00e9: qualidade da nutri\u00e7\u00e3o (escala cont\u00ednua, ex.: 0\u201310).</p> <p>Para que serve: proxy de alimenta\u00e7\u00e3o saud\u00e1vel; geralmente relevante.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma; manter como num\u00e9rica (s\u00f3 garantir faixa v\u00e1lida).</p> 2025-10-28T15:18:53.432492 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua (escala)</p> <p>O que \u00e9: n\u00edvel de atividade f\u00edsica (escala cont\u00ednua, ex.: 0\u201310).</p> <p>Para que serve: costuma ser uma das vari\u00e1veis mais importantes para is_fit.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma; manter como num\u00e9rica (garantir faixa v\u00e1lida).</p> 2025-10-28T15:18:53.509335 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria</p> <p>O que \u00e9: status de tabagismo (sim/n\u00e3o).</p> <p>Para que serve: fator de estilo de vida; pode ajudar a separar perfis.</p> <p>A\u00e7\u00e3o necess\u00e1ria: tipos mistos no bruto (\u201cyes/no\u201d e \u201c1/0\u201d). Padronizar para bin\u00e1rio num\u00e9rico (no\u21920, yes\u21921) e converter para int.</p> 2025-10-28T15:18:53.593632 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria</p> <p>O que \u00e9: g\u00eanero (F/M).</p> <p>Para que serve: poss\u00edvel moderador de outros efeitos; em geral fraco sozinho.</p> <p>A\u00e7\u00e3o necess\u00e1ria: codificar para num\u00e9rico (F\u21920, M\u21921) e converter para int.</p> 2025-10-28T15:18:53.630450 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria (target)</p> <p>O que \u00e9: r\u00f3tulo de condi\u00e7\u00e3o f\u00edsica (1 = fit, 0 = n\u00e3o fit).</p> <p>Para que serve: vari\u00e1vel dependente a ser prevista.</p> <p>A\u00e7\u00e3o necess\u00e1ria: checar balanceamento das classes.</p> 2025-10-28T15:18:53.687154 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"Exercicios/k-means/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Nesta etapa tratei e preparei os dados para treinar a \u00c1rvore de Decis\u00e3o. Antes do tratamento, a base apresentava valores ausentes em sleep_hours, tipos mistos em smokes (valores como yes/no e 0/1 ao mesmo tempo) e vari\u00e1veis categ\u00f3ricas em texto (gender com F/M). Abaixo, o que foi feito:</p> <p>\u2022 Padroniza\u00e7\u00e3o de categ\u00f3ricas</p> <ul> <li> <p>smokes: normalizei r\u00f3tulos e converti para bin\u00e1rio num\u00e9rico (no\u21920, yes\u21921, cobrindo tamb\u00e9m 0/1 em string).</p> </li> <li> <p>gender: converti F\u21920 e M\u21921.</p> </li> </ul> <p>\u2022 Valores ausentes</p> <ul> <li>sleep_hours: converti para num\u00e9rico e imputei a mediana.</li> </ul> <p>\u2022 Tipos e consist\u00eancia</p> <ul> <li>Garanti que as vari\u00e1veis cont\u00ednuas ficaram em formato num\u00e9rico, sem strings residuais/espac\u0327os.</li> </ul> <p>\u2022 Cria\u00e7\u00e3o de nova vari\u00e1vel</p> <ul> <li>Criei a vari\u00e1vel BMI (peso(kg) / altura(m)\u00b2) para avaliar seu impacto. Na explora\u00e7\u00e3o, mantenho height_cm e weight_kg para refer\u00eancia; na modelagem, comparo dois cen\u00e1rios: (A) sem BMI (altura + peso) e (B) com apenas BMI, evitando usar os tr\u00eas juntos no mesmo modelo para n\u00e3o introduzir redund\u00e2ncia.</li> </ul> Base originalTratamentoBase Tratada age height_cm weight_kg heart_rate blood_pressure sleep_hours nutrition_quality activity_index smokes gender is_fit 78 186 109 71.4 121.7 9.2 8.4 2.57 no F 1 60 190 111 84.6 131.7 4.6 2.81 2.37 0 M 1 48 153 59 60 109.1 10.4 0.26 3.29 no M 1 68 191 72 61.9 116.7 9.3 9.66 3.25 0 M 1 62 197 48 77.3 133.8 8.1 8.96 2.39 0 F 1 53 169 78 105.6 108.9 7.4 0.18 1.51 yes M 0 26 197 46 69.2 120.7 null 9.75 1.77 1 M 0 67 159 92 56.1 119 8.6 2.09 3.81 no M 1 34 173 112 53.9 136.8 6.0 6.83 1.32 0 M 0 29 191 54 55.6 115.1 9.2 9.36 2.95 no F 1 38 184 62 62.4 108.1 9.7 9.96 3.07 yes F 1 40 178 55 82.3 112.3 8.5 7.64 3.84 no M 1 50 161 109 72.6 136.3 7.7 5.8 1.76 yes F 0 79 153 74 96.7 130.9 null 6.32 2.62 0 M 0 45 150 78 52.2 113.1 6.9 6.51 4.68 0 F 1 <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\ndf[\"sleep_hours\"] = df[\"sleep_hours\"].fillna(df[\"sleep_hours\"].median())\n\ndf[\"smokes\"] = (\n    df[\"smokes\"].astype(str).str.strip().str.lower()\n      .map({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0})\n).astype(int)\n\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m**2)\ndf[\"bmi\"] = bmi.replace([float(\"inf\"), float(\"-inf\")], pd.NA).fillna(bmi.median())\n\nprint(df.sample(n=15).to_markdown(index=False))\n</code></pre> age height_cm weight_kg heart_rate blood_pressure sleep_hours nutrition_quality activity_index smokes gender is_fit bmi 31 184 98 68.6 128.1 8.1 0.79 2.06 1 0 0 28.9461 56 156 72 61.8 133.4 5.6 5.28 4.32 0 0 1 29.5858 46 184 82 79.5 118.4 5.2 5.11 4.43 0 1 1 24.2202 34 163 55 65.3 104.6 6.1 1.05 2.7 1 1 0 20.7008 19 160 117 80.5 122.8 8.9 7.47 4.9 0 1 1 45.7031 49 170 117 54 108.3 6.2 7.7 3.82 0 0 0 40.4844 66 181 52 68.4 114.8 4 9.69 4.82 1 1 1 15.8725 20 166 91 76.9 130.2 7.1 3.26 3.06 0 1 1 33.0237 65 199 108 78.3 103.8 10.3 1.29 1.14 1 1 1 27.272 79 199 107 82.5 117.5 9.1 1.42 3.67 0 0 1 27.0195 32 157 90 69.5 114.1 7.6 3.33 4.42 1 0 0 36.5126 28 167 75 80.7 113.2 6.8 2.8 3.68 0 0 1 26.8923 79 169 73 64.6 102 8.6 1.51 2.82 0 0 0 25.5593 64 153 62 77.7 99.9 7 9.11 2.76 0 0 1 26.4855 69 192 73 58.2 105.7 7.5 5.6 3.48 0 1 1 19.8025"},{"location":"Exercicios/k-means/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>Diferentemente dos modelos supervisionados, o K-Means \u00e9 um algoritmo n\u00e3o supervisionado e, portanto, n\u00e3o requer a separa\u00e7\u00e3o em treino e teste. Ap\u00f3s o pr\u00e9-processamento, utilizei todo o conjunto de dados para formar os clusters com base apenas nas vari\u00e1veis explicativas (idade, frequ\u00eancia card\u00edaca, press\u00e3o arterial, horas de sono, qualidade da nutri\u00e7\u00e3o, n\u00edvel de atividade f\u00edsica, tabagismo, g\u00eanero e o BMI). A vari\u00e1vel-alvo is_fit foi mantida de lado e utilizada apenas posteriormente para avaliar a correspond\u00eancia entre os clusters encontrados e as classes reais (\u201cfit\u201d vs. \u201cn\u00e3o fit\u201d).</p> <p>Como o K-Means \u00e9 sens\u00edvel \u00e0 escala, apliquei padroniza\u00e7\u00e3o (z-score) \u00e0s vari\u00e1veis num\u00e9ricas, garantindo que nenhum atributo dominasse a dist\u00e2ncia euclidiana. Al\u00e9m disso, para evitar redund\u00e2ncia, substitu\u00ed height_cm e weight_kg pela vari\u00e1vel derivada bmi. Dessa forma, os agrupamentos refletem padr\u00f5es de similaridade nos h\u00e1bitos e indicadores de sa\u00fade, e a valida\u00e7\u00e3o com is_fit serve apenas como refer\u00eancia externa de qualidade do clustering.</p> C\u00f3digo <p>Features: age, height_cm, weight_kg, heart_rate, blood_pressure, sleep_hours, nutrition_quality, activity_index, smokes, gender.</p> <p>Objetivo: servir de refer\u00eancia para comparar com a vers\u00e3o engenheirada. </p> <p>Mesma configura\u00e7\u00e3o de split (70/30, random_state=42, stratify=y).</p> <pre><code>import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\n# sleep_hours\ndf[\"sleep_hours\"] = pd.to_numeric(df[\"sleep_hours\"], errors=\"coerce\").fillna(df[\"sleep_hours\"].median())\n\n# smokes -&gt; 0/1\ndf[\"smokes\"] = (\n    df[\"smokes\"].astype(str).str.strip().str.lower()\n      .map({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0})\n).astype(int)\n\n# gender -&gt; 0/1\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\n# BMI\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m**2)\ndf[\"bmi\"] = bmi.replace([float(\"inf\"), float(\"-inf\")], pd.NA).fillna(bmi.median())\n\n# Features e alvo (y s\u00f3 para avalia\u00e7\u00e3o externa)\nnum_cols = [\"age\",\"heart_rate\",\"blood_pressure\",\"sleep_hours\",\"nutrition_quality\",\"activity_index\",\"bmi\"]\ncat_cols = [\"smokes\",\"gender\"]\ntarget = \"is_fit\"\n\nfor c in num_cols:\n    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(df[c].median())\n\nX_num = df[num_cols]\nX_cat = df[cat_cols]\n\n# padroniza s\u00f3 num\u00e9ricos\nscaler = StandardScaler()\nX_num_scaled = pd.DataFrame(scaler.fit_transform(X_num), columns=num_cols)\n\n# matriz final p/ K-Means\nX = pd.concat([X_num_scaled.reset_index(drop=True), X_cat.reset_index(drop=True)], axis=1).values\ny = df[target].astype(int).values\n\nprint(\"Shape X:\", X.shape)\nprint(\"Propor\u00e7\u00e3o 'is_fit'=1:\", y.mean())\nprint(\"Observa\u00e7\u00e3o: K-Means usa APENAS X; y \u00e9 para avaliar depois.\")\n</code></pre>"},{"location":"Exercicios/k-means/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"ModeloC\u00f3digo 2025-10-28T15:18:53.875978 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# --- Carregar base ---\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\n# --- Pr\u00e9-processamento ---\ndf[\"sleep_hours\"] = pd.to_numeric(df[\"sleep_hours\"], errors=\"coerce\").fillna(df[\"sleep_hours\"].median())\n\ndf[\"smokes\"] = (\n    df[\"smokes\"].astype(str).str.strip().str.lower()\n      .map({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0})\n).astype(int)\n\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\n# BMI\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m**2)\ndf[\"bmi\"] = bmi.replace([float(\"inf\"), float(\"-inf\")], pd.NA).fillna(bmi.median())\n\n# Features (X) e alvo (y apenas para avalia\u00e7\u00e3o futura)\nnum_cols = [\"age\", \"heart_rate\", \"blood_pressure\", \"sleep_hours\",\n            \"nutrition_quality\", \"activity_index\", \"bmi\"]\ncat_cols = [\"smokes\", \"gender\"]\ntarget = \"is_fit\"\n\nfor c in num_cols:\n    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(df[c].median())\n\nX_num = df[num_cols]\nX_cat = df[cat_cols]\n\nscaler = StandardScaler()\nX_num_scaled = pd.DataFrame(scaler.fit_transform(X_num), columns=num_cols)\n\nX = pd.concat([X_num_scaled.reset_index(drop=True),\n               X_cat.reset_index(drop=True)], axis=1).values\ny = df[target].astype(int).values\n\n# --- K-Means ---\nkmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300,\n                random_state=42, n_init=10)\nlabels = kmeans.fit_predict(X)\n\n# --- PCA p/ visualiza\u00e7\u00e3o ---\npca = PCA(n_components=2, random_state=42)\nX_2d = pca.fit_transform(X)\n\n# --- Plot ---\nplt.figure(figsize=(12, 10))\nplt.scatter(X_2d[:, 0], X_2d[:, 1], c=labels, cmap='viridis', s=50, alpha=0.7)\n# projeta centr\u00f3ides para o espa\u00e7o PCA\ncentroids_2d = pca.transform(kmeans.cluster_centers_)\nplt.scatter(centroids_2d[:, 0], centroids_2d[:, 1],\n            c='red', marker='*', s=200, label='Centroids (PCA proj.)')\n\nplt.title('K-Means Clustering (Fitness Dataset)')\nplt.xlabel('PCA 1')\nplt.ylabel('PCA 2')\nplt.legend()\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\nplt.close()\n</code></pre>"},{"location":"Exercicios/k-means/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>O algoritmo K-Means foi aplicado com k = 2, refletindo a natureza bin\u00e1ria da vari\u00e1vel is_fit (fit e n\u00e3o fit). A an\u00e1lise gr\u00e1fica mostra que os clusters foram formados, mas com forte sobreposi\u00e7\u00e3o entre os grupos. Isso significa que, embora o algoritmo tenha conseguido identificar padr\u00f5es de proximidade nos dados, a separa\u00e7\u00e3o entre os perfis de indiv\u00edduos com boa condi\u00e7\u00e3o f\u00edsica e os demais n\u00e3o \u00e9 n\u00edtida.</p> <p>O posicionamento dos centr\u00f3ides indica regi\u00f5es m\u00e9dias de concentra\u00e7\u00e3o, mas a distribui\u00e7\u00e3o densa e misturada dos pontos em torno deles revela que as vari\u00e1veis utilizadas \u2014 como BMI, atividade f\u00edsica, nutri\u00e7\u00e3o e indicadores de sa\u00fade \u2014 possuem relev\u00e2ncia, mas n\u00e3o criam divis\u00f5es claras o suficiente para que o K-Means consiga formar agrupamentos bem distintos. Essa caracter\u00edstica \u00e9 comum em bases de dados relacionadas a h\u00e1bitos e sa\u00fade, em que m\u00faltiplos fatores se combinam de maneira complexa e n\u00e3o linear.</p>"},{"location":"Exercicios/k-means/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O uso do K-Means permitiu uma explora\u00e7\u00e3o inicial da base, evidenciando como os indiv\u00edduos se distribuem em grupos de acordo com seus atributos de sa\u00fade e estilo de vida. Apesar da simplicidade e efici\u00eancia do algoritmo, os resultados mostram que os clusters obtidos n\u00e3o correspondem perfeitamente \u00e0 divis\u00e3o real entre \u201cfit\u201d e \u201cn\u00e3o fit\u201d.</p> <p>De forma geral, a an\u00e1lise refor\u00e7a que, embora o K-Means seja \u00fatil para identificar padr\u00f5es gerais e tend\u00eancias de proximidade, sua capacidade de representar a vari\u00e1vel is_fit de forma fiel \u00e9 limitada. Para an\u00e1lises mais robustas, seria necess\u00e1rio considerar t\u00e9cnicas adicionais, como algoritmos supervisionados (\u00c1rvore de Decis\u00e3o, KNN ou Random Forest), ou mesmo explorar varia\u00e7\u00f5es de clustering que lidem melhor com sobreposi\u00e7\u00e3o de classes. Ainda assim, o exerc\u00edcio com K-Means foi importante para oferecer uma perspectiva n\u00e3o supervisionada da estrutura dos dados e validar a dificuldade inerente da tarefa de classifica\u00e7\u00e3o no contexto do dataset de fitness.</p>"},{"location":"Exercicios/knn/main/","title":"KNN","text":""},{"location":"Exercicios/knn/main/#introducao-ao-knn","title":"Introdu\u00e7\u00e3o ao KNN","text":"<p>O algoritmo K-Nearest Neighbors (KNN) foi utilizado como alternativa para realizar tarefas de classifica\u00e7\u00e3o. Esse m\u00e9todo classifica uma nova observa\u00e7\u00e3o com base nos exemplos mais pr\u00f3ximos do conjunto de treino, considerando a similaridade entre seus atributos. Por sua simplicidade e flexibilidade, o KNN n\u00e3o exige pressupostos sobre a distribui\u00e7\u00e3o dos dados e oferece uma an\u00e1lise fundamentada na proximidade entre inst\u00e2ncias, funcionando como complemento \u00e0s previs\u00f5es obtidas com a \u00e1rvore de decis\u00e3o.</p>"},{"location":"Exercicios/knn/main/#descricao-sobre-o-banco","title":"Descri\u00e7\u00e3o sobre o banco","text":"<p>Para mais informa\u00e7\u00f5es, cheque a p\u00e1gina sobre \u00c1rvore de decis\u00e3o, aqui tem toda a explica\u00e7\u00e3o necess\u00e1ria para compreender as vari\u00e1veis e as outras coisas.</p>"},{"location":"Exercicios/knn/main/#analise-dos-dados","title":"An\u00e1lise dos dados","text":"Ageheight_cmweight_kgheart_rateblood_pressureSleep_HoursNutrition_qualityActivity_indexsmokesgenderis_fit <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: idade em anos.</p> <p>Para que serve: pode relacionar-se com h\u00e1bitos e condi\u00e7\u00e3o f\u00edsica.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; s\u00f3 checar faixas implaus\u00edveis (n\u00e3o observei no geral).</p> 2025-10-28T15:18:54.163048 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: altura em cent\u00edmetros.</p> <p>Para que serve: isoladamente costuma ter pouco poder; combinada ao peso forma o BMI.</p> <p>A\u00e7\u00e3o necess\u00e1ria: checar valores muito fora do plaus\u00edvel. Sugest\u00e3o: considerar substituir altura e peso por bmi(\u00cdndice de Massa Corporal).</p> 2025-10-28T15:18:54.230787 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: peso em quilogramas.</p> <p>Para que serve: junto com a altura permite calcular BMI = peso(kg) / (altura(m))\u00b2, que costuma ser mais informativo para a \u00e1rvore.</p> <p>A\u00e7\u00e3o necess\u00e1ria: manter como num\u00e9rica ou criar bmi e remover height_cm/weight_kg das features (deixando s\u00f3 o bmi).</p> 2025-10-28T15:18:54.317172 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: frequ\u00eancia card\u00edaca (bpm).</p> <p>Para que serve: indicador de condicionamento cardiovascular; pode ajudar na separa\u00e7\u00e3o das classes.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; apenas conferir plausibilidade de valores extremos.</p> 2025-10-28T15:18:54.371242 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: medida sint\u00e9tica de press\u00e3o arterial fornecida pelo dataset.</p> <p>Para que serve: sinal de sa\u00fade geral que pode complementar a predi\u00e7\u00e3o.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; s\u00f3 verificar extremos muito fora do usual.</p> 2025-10-28T15:18:54.553864 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: horas de sono por dia.</p> <p>Para que serve: h\u00e1bito de descanso; costuma ter correla\u00e7\u00e3o com \u201cestar fit\u201d.</p> <p>A\u00e7\u00e3o necess\u00e1ria: possui valores ausentes (160 valores); imputar com a mediana.</p> 2025-10-28T15:18:54.626775 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua (escala)</p> <p>O que \u00e9: qualidade da nutri\u00e7\u00e3o (escala cont\u00ednua, ex.: 0\u201310).</p> <p>Para que serve: proxy de alimenta\u00e7\u00e3o saud\u00e1vel; geralmente relevante.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma; manter como num\u00e9rica (s\u00f3 garantir faixa v\u00e1lida).</p> 2025-10-28T15:18:54.703374 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua (escala)</p> <p>O que \u00e9: n\u00edvel de atividade f\u00edsica (escala cont\u00ednua, ex.: 0\u201310).</p> <p>Para que serve: costuma ser uma das vari\u00e1veis mais importantes para is_fit.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma; manter como num\u00e9rica (garantir faixa v\u00e1lida).</p> 2025-10-28T15:18:54.779341 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria</p> <p>O que \u00e9: status de tabagismo (sim/n\u00e3o).</p> <p>Para que serve: fator de estilo de vida; pode ajudar a separar perfis.</p> <p>A\u00e7\u00e3o necess\u00e1ria: tipos mistos no bruto (\u201cyes/no\u201d e \u201c1/0\u201d). Padronizar para bin\u00e1rio num\u00e9rico (no\u21920, yes\u21921) e converter para int.</p> 2025-10-28T15:18:54.863981 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria</p> <p>O que \u00e9: g\u00eanero (F/M).</p> <p>Para que serve: poss\u00edvel moderador de outros efeitos; em geral fraco sozinho.</p> <p>A\u00e7\u00e3o necess\u00e1ria: codificar para num\u00e9rico (F\u21920, M\u21921) e converter para int.</p> 2025-10-28T15:18:54.892335 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria (target)</p> <p>O que \u00e9: r\u00f3tulo de condi\u00e7\u00e3o f\u00edsica (1 = fit, 0 = n\u00e3o fit).</p> <p>Para que serve: vari\u00e1vel dependente a ser prevista.</p> <p>A\u00e7\u00e3o necess\u00e1ria: checar balanceamento das classes.</p> 2025-10-28T15:18:54.946743 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"Exercicios/knn/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Nesta etapa tratei e preparei os dados para treinar a \u00c1rvore de Decis\u00e3o. Antes do tratamento, a base apresentava valores ausentes em sleep_hours, tipos mistos em smokes (valores como yes/no e 0/1 ao mesmo tempo) e vari\u00e1veis categ\u00f3ricas em texto (gender com F/M). Abaixo, o que foi feito:</p> <p>\u2022 Padroniza\u00e7\u00e3o de categ\u00f3ricas</p> <ul> <li> <p>smokes: normalizei r\u00f3tulos e converti para bin\u00e1rio num\u00e9rico (no\u21920, yes\u21921, cobrindo tamb\u00e9m 0/1 em string).</p> </li> <li> <p>gender: converti F\u21920 e M\u21921.</p> </li> </ul> <p>\u2022 Valores ausentes</p> <ul> <li>sleep_hours: converti para num\u00e9rico e imputei a mediana.</li> </ul> <p>\u2022 Tipos e consist\u00eancia</p> <ul> <li>Garanti que as vari\u00e1veis cont\u00ednuas ficaram em formato num\u00e9rico, sem strings residuais/espac\u0327os.</li> </ul> <p>\u2022 Cria\u00e7\u00e3o de nova vari\u00e1vel</p> <ul> <li>Criei a vari\u00e1vel BMI (peso(kg) / altura(m)\u00b2) para avaliar seu impacto. Na explora\u00e7\u00e3o, mantenho height_cm e weight_kg para refer\u00eancia; na modelagem, comparo dois cen\u00e1rios: (A) sem BMI (altura + peso) e (B) com apenas BMI, evitando usar os tr\u00eas juntos no mesmo modelo para n\u00e3o introduzir redund\u00e2ncia.</li> </ul> Base originalTratamentoBase Tratada age height_cm weight_kg heart_rate blood_pressure sleep_hours nutrition_quality activity_index smokes gender is_fit 52 168 95 60.2 128.4 7.3 3.87 1.34 no M 0 37 182 73 59.4 108.5 8.8 4.11 1.87 0 M 1 22 150 95 67 121.6 6.2 2.54 1.58 yes F 0 58 191 62 59 136.6 8.8 5.74 1.94 no F 0 39 190 65 68.3 107.5 7.3 8.3 1.52 yes F 0 79 199 107 82.5 117.5 9.1 1.42 3.67 0 F 1 65 162 99 69.1 105.5 6.3 6.87 4.18 yes F 0 45 153 98 75.9 125.2 8.8 3.72 1.5 0 M 0 42 158 84 62.6 129.3 6.1 3.82 2.95 yes F 0 19 180 96 98.8 95.9 7.4 2.39 3.56 no F 0 48 193 101 96.6 121.2 7.5 6.38 3.6 0 M 1 29 187 71 68.4 117.1 6.0 9.95 3.61 0 F 1 31 166 81 68 128.8 8.3 0.88 2.88 no M 0 62 152 91 59 105.7 9.0 4.16 4 0 M 1 43 181 91 96.1 121.4 null 3.99 4.52 1 M 1 <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\ndf[\"sleep_hours\"] = df[\"sleep_hours\"].fillna(df[\"sleep_hours\"].median())\n\ndf[\"smokes\"] = (\n    df[\"smokes\"].astype(str).str.strip().str.lower()\n      .map({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0})\n).astype(int)\n\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m**2)\ndf[\"bmi\"] = bmi.replace([float(\"inf\"), float(\"-inf\")], pd.NA).fillna(bmi.median())\n\nprint(df.sample(n=15).to_markdown(index=False))\n</code></pre> age height_cm weight_kg heart_rate blood_pressure sleep_hours nutrition_quality activity_index smokes gender is_fit bmi 77 171 90 66.5 104.8 4.6 9.2 1.98 0 0 0 30.7787 79 184 91 73.2 115.4 5.6 1.96 4.46 0 0 0 26.8785 31 198 100 82.9 108.4 9.1 8.02 2.9 0 1 1 25.5076 40 183 87 72.2 124.2 8.9 6.67 3.59 0 1 1 25.9787 75 191 109 66.4 128.8 11.4 2.98 3.87 0 0 0 29.8786 78 178 113 85.4 134.3 6.6 9.2 2.75 1 1 0 35.6647 40 161 108 53.1 125.3 6.7 1.58 3.31 1 1 0 41.6651 21 164 110 60.7 131.2 7.3 0.38 4.06 0 1 1 40.8983 38 188 57 81.2 110.6 6.6 8.47 4.96 0 1 1 16.1272 66 174 82 75.9 128.8 8.1 7.23 3.47 0 0 1 27.0842 52 171 54 53.8 109.5 6.8 10 1.3 1 1 0 18.4672 75 152 118 67.9 110.9 7.6 4.56 2.67 0 0 0 51.0734 43 154 69 73.8 133.2 6.6 2.66 2.05 0 1 0 29.0943 35 158 104 68.1 118.1 5.6 6.92 1.45 0 0 0 41.66 56 164 108 70.1 140.9 9.1 4.15 2.06 0 0 0 40.1547"},{"location":"Exercicios/knn/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>Para o modelo KNN, optei por separar o conjunto em treino (80%) e teste (20%), de forma a avaliar o desempenho do classificador em dados n\u00e3o vistos. O par\u00e2metro random_state=42 foi utilizado para garantir reprodutibilidade, e stratify=y assegurou que a propor\u00e7\u00e3o entre as classes (is_fit = 0 e is_fit = 1) fosse preservada em ambas as parti\u00e7\u00f5es.</p> <p>Antes da divis\u00e3o, o pr\u00e9-processamento j\u00e1 havia sido realizado: imputa\u00e7\u00e3o da mediana em sleep_hours, padroniza\u00e7\u00e3o de smokes (0/1), codifica\u00e7\u00e3o de gender (0/1) e cria\u00e7\u00e3o da vari\u00e1vel bmi em substitui\u00e7\u00e3o \u00e0s vari\u00e1veis originais height_cm e weight_kg. Como o KNN \u00e9 sens\u00edvel a diferen\u00e7as de escala, tamb\u00e9m foi aplicada a padroniza\u00e7\u00e3o dos atributos num\u00e9ricos ap\u00f3s a defini\u00e7\u00e3o das features finais.</p> <p>Essa estrat\u00e9gia garante que o modelo seja treinado em um subconjunto representativo e avaliado de maneira justa, evitando que a acur\u00e1cia reflita apenas o aprendizado sobre o conjunto total de dados.</p> C\u00f3digo <p>Features: age, height_cm, weight_kg, heart_rate, blood_pressure, sleep_hours, nutrition_quality, activity_index, smokes, gender.</p> <p>Objetivo: servir de refer\u00eancia para comparar com a vers\u00e3o engenheirada. </p> <p>Mesma configura\u00e7\u00e3o de split (70/30, random_state=42, stratify=y).</p> <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Carregar base\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\n# Tratamento\ndf[\"sleep_hours\"] = pd.to_numeric(df[\"sleep_hours\"], errors=\"coerce\").fillna(df[\"sleep_hours\"].median())\n\ndf[\"smokes\"] = (\n    df[\"smokes\"].astype(str).str.strip().str.lower()\n      .map({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0})\n).astype(int)\n\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\n# Criar BMI e substituir height/weight\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m**2)\ndf[\"bmi\"] = bmi.replace([float(\"inf\"), float(\"-inf\")], pd.NA).fillna(bmi.median())\n\n# Features e alvo\nnum_cols = [\"age\", \"heart_rate\", \"blood_pressure\", \"sleep_hours\",\n            \"nutrition_quality\", \"activity_index\", \"bmi\"]\ncat_cols = [\"smokes\", \"gender\"]\ntarget = \"is_fit\"\n\n# Garantir num\u00e9ricos v\u00e1lidos\nfor c in num_cols:\n    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(df[c].median())\n\nX_num = df[num_cols]\nX_cat = df[cat_cols]\n\n# Padronizar atributos num\u00e9ricos\nscaler = StandardScaler()\nX_num_scaled = pd.DataFrame(scaler.fit_transform(X_num), columns=num_cols)\n\n# Concatenar\nX = pd.concat([X_num_scaled.reset_index(drop=True),\n               X_cat.reset_index(drop=True)], axis=1).values\ny = df[target].astype(int).values\n\n# Divis\u00e3o treino/teste (80/20)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,\n    random_state=42,\n    stratify=y\n)\n\nprint(\"Tamanho treino:\", X_train.shape[0])\nprint(\"Tamanho teste:\", X_test.shape[0])\nprint(\"Propor\u00e7\u00e3o classes treino:\", y_train.mean())\nprint(\"Propor\u00e7\u00e3o classes teste:\", y_test.mean())\n</code></pre>"},{"location":"Exercicios/knn/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"ModeloC\u00f3digo <p>Acur\u00e1cia (KNN k=5): 0.71</p> <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\n\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\n# Tratamento dos dados\ndf[\"sleep_hours\"] = pd.to_numeric(df[\"sleep_hours\"], errors=\"coerce\")\ndf[\"sleep_hours\"] = df[\"sleep_hours\"].fillna(df[\"sleep_hours\"].median())\ndf[\"smokes\"] = df[\"smokes\"].replace({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0}).astype(int)\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\n# bmi = weight_kg / (height_m^2)\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m ** 2)\ndf[\"bmi\"] = (\n    bmi.replace([float(\"inf\"), float(\"-inf\")], pd.NA)\n       .fillna(bmi.median())\n)\n\n\n# Features e target\nnum_cols = [\n    \"age\", \"heart_rate\", \"blood_pressure\",\n    \"sleep_hours\", \"nutrition_quality\", \"activity_index\", \"bmi\"\n]\ncat_cols = [\"smokes\", \"gender\"]\ntarget = \"is_fit\"\n\n# Garantir tipos num\u00e9ricos\nfor c in num_cols:\n    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n    df[c] = df[c].fillna(df[c].median())\n\nX_num = df[num_cols]\nX_cat = df[cat_cols]\n\n# Padroniza\u00e7\u00e3o dos dados num\u00e9ricos\nscaler = StandardScaler()\nX_num = pd.DataFrame(scaler.fit_transform(X_num), columns=num_cols)\n\n# Junta tudo\nX = pd.concat([X_num, X_cat.reset_index(drop=True)], axis=1).values\ny = df[target].astype(int).values\n\n# Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.20, random_state=42, stratify=y\n)\n\nclass KNNClassifier:\n    def __init__(self, k=5):\n        self.k = k\n\n    def fit(self, X, y):\n        self.X_train = X\n        self.y_train = np.array(y)\n\n    def predict(self, X):\n        return np.array([self._predict(x) for x in X])\n\n    def _predict(self, x):\n        distances = np.sqrt(((self.X_train - x) ** 2).sum(axis=1))\n        k_idx = np.argsort(distances)[:self.k]\n        k_labels = self.y_train[k_idx]\n        vals, counts = np.unique(k_labels, return_counts=True)\n        return vals[np.argmax(counts)]\n\n# Treinar e avaliar\nknn = KNNClassifier(k=5)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\nacc = accuracy_score(y_test, y_pred)\nprint(f\"Acur\u00e1cia (KNN k={knn.k}): {acc:.2f}\")\n</code></pre>"},{"location":"Exercicios/knn/main/#usando-o-scikit-learn","title":"Usando o Scikit-Learn","text":"ResultadoC\u00f3digo <p>Acur\u00e1cia: 0.6250  2025-10-28T15:18:55.352332 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score\n\n# === Carregar e tratar como na base_tratada ===\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\n# sleep_hours -&gt; mediana\ndf[\"sleep_hours\"] = pd.to_numeric(df[\"sleep_hours\"], errors=\"coerce\")\ndf[\"sleep_hours\"] = df[\"sleep_hours\"].fillna(df[\"sleep_hours\"].median())\n\n# smokes -&gt; normaliza r\u00f3tulos e converte p/ 0/1\ndf[\"smokes\"] = (\n    df[\"smokes\"].astype(str).str.strip().str.lower()\n      .map({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0})\n).astype(int)\n\n# gender -&gt; F=0, M=1\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\n# bmi = weight_kg / (height_m^2)\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m ** 2)\ndf[\"bmi\"] = (\n    bmi.replace([float(\"inf\"), float(\"-inf\")], pd.NA)\n       .fillna(bmi.median())\n)\n\n# === Features e alvo ===\n# Usa BMI e remove height_cm/weight_kg para evitar redund\u00e2ncia\nnum_cols = [\n    \"age\", \"heart_rate\", \"blood_pressure\", \"sleep_hours\",\n    \"nutrition_quality\", \"activity_index\", \"bmi\"\n]\ncat_cols = [\"smokes\", \"gender\"]\ntarget = \"is_fit\"\n\n# Garantir num\u00e9ricos v\u00e1lidos nas cont\u00ednuas\nfor c in num_cols:\n    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n    df[c] = df[c].fillna(df[c].median())\n\nX_num = df[num_cols]\nX_cat = df[cat_cols]\n\n# Padroniza\u00e7\u00e3o (KNN \u00e9 sens\u00edvel \u00e0 escala)\nscaler = StandardScaler()\nX_num_scaled = pd.DataFrame(scaler.fit_transform(X_num), columns=num_cols)\n\n# Matriz final\nX = pd.concat([X_num_scaled.reset_index(drop=True),\n               X_cat.reset_index(drop=True)], axis=1).values\ny = df[target].astype(int).values\n\n# Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# PCA 2D s\u00f3 para visualiza\u00e7\u00e3o/decis\u00e3o do gr\u00e1fico\npca = PCA(n_components=2, random_state=42)\nX_train_2d = pca.fit_transform(X_train)\nX_test_2d = pca.transform(X_test)\n\n# KNN\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train_2d, y_train)\npred = knn.predict(X_test_2d)\n\n# M\u00e9tricas\nacc = accuracy_score(y_test, pred)\nbacc = balanced_accuracy_score(y_test, pred)\nprint(f\"Acur\u00e1cia: {acc:.4f}\")\n\n# Plot\nplt.figure(figsize=(12, 10))\nh = 0.05\nx_min, x_max = X_train_2d[:, 0].min() - 1, X_train_2d[:, 0].max() + 1\ny_min, y_max = X_train_2d[:, 1].min() - 1, X_train_2d[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu, alpha=0.3)\nsns.scatterplot(\n    x=X_train_2d[:, 0], y=X_train_2d[:, 1], hue=y_train,\n    palette=\"deep\", s=100, edgecolor=\"k\", alpha=0.8, legend=True\n)\n\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.title(\"KNN Decision Boundary (Fitness Dataset, com BMI)\")\nplt.tight_layout()\n\n# Renderiza 1 SVG no site e fecha a figura\nbuf = StringIO()\nplt.savefig(buf, format=\"svg\", bbox_inches=\"tight\", transparent=True)\nprint(buf.getvalue())\nplt.close()\n</code></pre>"},{"location":"Exercicios/knn/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>O modelo KNN, configurado com k = 5, apresentou uma acur\u00e1cia de aproximadamente 62% no conjunto de teste, com balanced accuracy em torno de 59%. Isso significa que o desempenho ficou apenas um pouco acima do acaso (50%), refletindo a dificuldade do algoritmo em distinguir corretamente entre indiv\u00edduos classificados como \u201cfit\u201d e \u201cn\u00e3o fit\u201d.</p> <p>A visualiza\u00e7\u00e3o da fronteira de decis\u00e3o confirma esse resultado: as classes aparecem bastante sobrepostas no espa\u00e7o de duas dimens\u00f5es (ap\u00f3s PCA), e a divis\u00e3o entre elas n\u00e3o \u00e9 n\u00edtida. Esse comportamento indica que as vari\u00e1veis utilizadas (idade, indicadores de sa\u00fade, h\u00e1bitos de sono, nutri\u00e7\u00e3o, atividade f\u00edsica, tabagismo, g\u00eanero e BMI) possuem alguma relev\u00e2ncia, mas n\u00e3o oferecem separa\u00e7\u00e3o clara o suficiente para que o KNN construa regi\u00f5es bem definidas para cada classe. Al\u00e9m disso, a irregularidade da fronteira de decis\u00e3o ressalta a sensibilidade do m\u00e9todo a ru\u00eddos e \u00e0 distribui\u00e7\u00e3o dos dados, algo esperado nesse tipo de problema.</p>"},{"location":"Exercicios/knn/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O uso do KNN para prever a condi\u00e7\u00e3o f\u00edsica (fit vs. n\u00e3o fit) demonstrou resultados modestos, mas ainda v\u00e1lidos como exerc\u00edcio de classifica\u00e7\u00e3o e compara\u00e7\u00e3o com outros algoritmos, como a \u00e1rvore de decis\u00e3o. Apesar da simplicidade e da interpreta\u00e7\u00e3o intuitiva do m\u00e9todo, a an\u00e1lise gr\u00e1fica mostrou que as classes s\u00e3o altamente sobrepostas, o que limita a capacidade do modelo de generalizar.</p> <p>De maneira geral, os resultados indicam que o KNN pode servir como uma abordagem inicial para explorar o dataset, mas melhorias dependem de ajustes nos hiperpar\u00e2metros (como o valor de k), da cria\u00e7\u00e3o de novas features ou da aplica\u00e7\u00e3o de modelos mais robustos, capazes de lidar melhor com a complexidade e o ru\u00eddo dos dados.</p>"},{"location":"Exercicios/metricasdeavl/main/","title":"M\u00e9tricas de Avalia\u00e7\u00e3o","text":""},{"location":"Exercicios/metricasdeavl/main/#indtorucao","title":"Indtoru\u00e7\u00e3o","text":""},{"location":"Exercicios/random_forest/main/","title":"Random Forest","text":""},{"location":"Exercicios/random_forest/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>A Random Forest \u00e9 um m\u00e9todo de aprendizado supervisionado baseado em conjunto de \u00e1rvores de decis\u00e3o. A ideia central \u00e9 treinar v\u00e1rias \u00e1rvores em amostras bootstrap do conjunto de treino, introduzindo aleatoriedade tanto nas amostras quanto na sele\u00e7\u00e3o de atributos em cada divis\u00e3o. A predi\u00e7\u00e3o final resulta do voto da maioria (classifica\u00e7\u00e3o) ou da m\u00e9dia (regress\u00e3o). Essa estrat\u00e9gia reduz overfitting t\u00edpico de \u00e1rvores individuais, melhora a generaliza\u00e7\u00e3o e mant\u00e9m boa interpretabilidade via import\u00e2ncia de atributos. Al\u00e9m disso, por ser baseada em \u00e1rvores, lida naturalmente com rela\u00e7\u00f5es n\u00e3o lineares e intera\u00e7\u00f5es entre vari\u00e1veis e n\u00e3o exige padroniza\u00e7\u00e3o das features para funcionar \u2014 embora possamos manter o mesmo pipeline de pr\u00e9-processamento para consist\u00eancia com os outros modelos do projeto.</p>"},{"location":"Exercicios/random_forest/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":""},{"location":"Exercicios/random_forest/main/#o-dataset","title":"O Dataset","text":"<p>Para esse projeto foi utilizada o Dataset Fitness Classification Dataset. Essa Base de dados posu\u00ed 2.000 linhas e 11 colunas. A vari\u00e1vel dependente que ser\u00e1 usada como objeto de classifica\u00e7\u00e3o \u00e9 a is_fit, ela indica se a pessoa \u00e9 fit (1) ou n\u00e3o fit (0).</p>"},{"location":"Exercicios/random_forest/main/#analise-dos-dados","title":"An\u00e1lise dos dados","text":"Ageheight_cmweight_kgheart_rateblood_pressureSleep_HoursNutrition_qualityActivity_indexsmokesgenderis_fit <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: idade em anos.</p> <p>Para que serve: pode relacionar-se com h\u00e1bitos e condi\u00e7\u00e3o f\u00edsica.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; s\u00f3 checar faixas implaus\u00edveis (n\u00e3o observei no geral).</p> 2025-10-28T15:18:55.640723 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: altura em cent\u00edmetros.</p> <p>Para que serve: isoladamente costuma ter pouco poder; combinada ao peso forma o BMI.</p> <p>A\u00e7\u00e3o necess\u00e1ria: checar valores muito fora do plaus\u00edvel. Sugest\u00e3o: considerar substituir altura e peso por bmi(\u00cdndice de Massa Corporal).</p> 2025-10-28T15:18:55.708982 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: peso em quilogramas.</p> <p>Para que serve: junto com a altura permite calcular BMI = peso(kg) / (altura(m))\u00b2, que costuma ser mais informativo para a \u00e1rvore.</p> <p>A\u00e7\u00e3o necess\u00e1ria: manter como num\u00e9rica ou criar bmi e remover height_cm/weight_kg das features (deixando s\u00f3 o bmi).</p> 2025-10-28T15:18:55.795187 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: frequ\u00eancia card\u00edaca (bpm).</p> <p>Para que serve: indicador de condicionamento cardiovascular; pode ajudar na separa\u00e7\u00e3o das classes.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; apenas conferir plausibilidade de valores extremos.</p> 2025-10-28T15:18:55.849942 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: medida sint\u00e9tica de press\u00e3o arterial fornecida pelo dataset.</p> <p>Para que serve: sinal de sa\u00fade geral que pode complementar a predi\u00e7\u00e3o.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma obrigat\u00f3ria; s\u00f3 verificar extremos muito fora do usual.</p> 2025-10-28T15:18:55.936101 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua</p> <p>O que \u00e9: horas de sono por dia.</p> <p>Para que serve: h\u00e1bito de descanso; costuma ter correla\u00e7\u00e3o com \u201cestar fit\u201d.</p> <p>A\u00e7\u00e3o necess\u00e1ria: possui valores ausentes (160 valores); imputar com a mediana.</p> 2025-10-28T15:18:56.009668 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua (escala)</p> <p>O que \u00e9: qualidade da nutri\u00e7\u00e3o (escala cont\u00ednua, ex.: 0\u201310).</p> <p>Para que serve: proxy de alimenta\u00e7\u00e3o saud\u00e1vel; geralmente relevante.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma; manter como num\u00e9rica (s\u00f3 garantir faixa v\u00e1lida).</p> 2025-10-28T15:18:56.085504 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: num\u00e9rica cont\u00ednua (escala)</p> <p>O que \u00e9: n\u00edvel de atividade f\u00edsica (escala cont\u00ednua, ex.: 0\u201310).</p> <p>Para que serve: costuma ser uma das vari\u00e1veis mais importantes para is_fit.</p> <p>A\u00e7\u00e3o necess\u00e1ria: nenhuma; manter como num\u00e9rica (garantir faixa v\u00e1lida).</p> 2025-10-28T15:18:56.160451 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria</p> <p>O que \u00e9: status de tabagismo (sim/n\u00e3o).</p> <p>Para que serve: fator de estilo de vida; pode ajudar a separar perfis.</p> <p>A\u00e7\u00e3o necess\u00e1ria: tipos mistos no bruto (\u201cyes/no\u201d e \u201c1/0\u201d). Padronizar para bin\u00e1rio num\u00e9rico (no\u21920, yes\u21921) e converter para int.</p> 2025-10-28T15:18:56.244451 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria</p> <p>O que \u00e9: g\u00eanero (F/M).</p> <p>Para que serve: poss\u00edvel moderador de outros efeitos; em geral fraco sozinho.</p> <p>A\u00e7\u00e3o necess\u00e1ria: codificar para num\u00e9rico (F\u21920, M\u21921) e converter para int.</p> 2025-10-28T15:18:56.272869 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Tipo: categ\u00f3rica bin\u00e1ria (target)</p> <p>O que \u00e9: r\u00f3tulo de condi\u00e7\u00e3o f\u00edsica (1 = fit, 0 = n\u00e3o fit).</p> <p>Para que serve: vari\u00e1vel dependente a ser prevista.</p> <p>A\u00e7\u00e3o necess\u00e1ria: checar balanceamento das classes.</p> 2025-10-28T15:18:56.326819 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"Exercicios/random_forest/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Nesta etapa tratei e preparei os dados para treinar a \u00c1rvore de Decis\u00e3o. Antes do tratamento, a base apresentava valores ausentes em sleep_hours, tipos mistos em smokes (valores como yes/no e 0/1 ao mesmo tempo) e vari\u00e1veis categ\u00f3ricas em texto (gender com F/M). Abaixo, o que foi feito:</p> <p>\u2022 Padroniza\u00e7\u00e3o de categ\u00f3ricas</p> <ul> <li> <p>smokes: normalizei r\u00f3tulos e converti para bin\u00e1rio num\u00e9rico (no\u21920, yes\u21921, cobrindo tamb\u00e9m 0/1 em string).</p> </li> <li> <p>gender: converti F\u21920 e M\u21921.</p> </li> </ul> <p>\u2022 Valores ausentes</p> <ul> <li>sleep_hours: converti para num\u00e9rico e imputei a mediana.</li> </ul> <p>\u2022 Tipos e consist\u00eancia</p> <ul> <li>Garanti que as vari\u00e1veis cont\u00ednuas ficaram em formato num\u00e9rico, sem strings residuais/espac\u0327os.</li> </ul> <p>\u2022 Cria\u00e7\u00e3o de nova vari\u00e1vel</p> <ul> <li>Criei a vari\u00e1vel BMI (peso(kg) / altura(m)\u00b2) para avaliar seu impacto. Na explora\u00e7\u00e3o, mantenho height_cm e weight_kg para refer\u00eancia; na modelagem, comparo dois cen\u00e1rios: (A) sem BMI (altura + peso) e (B) com apenas BMI, evitando usar os tr\u00eas juntos no mesmo modelo para n\u00e3o introduzir redund\u00e2ncia.</li> </ul> Base originalTratamentoBase Tratada age height_cm weight_kg heart_rate blood_pressure sleep_hours nutrition_quality activity_index smokes gender is_fit 66 181 84 69.6 132.3 5.3 5.75 1.09 0 M 0 73 163 77 64.6 98.6 null 5.71 4.38 yes M 0 25 157 90 96.9 108.3 null 3.72 1.24 yes M 0 54 189 87 69.3 113 5.8 6.1 3.43 0 M 1 79 169 46 58.7 105.1 null 1.83 1.92 no M 0 18 193 96 65.2 131.5 10.5 6.67 2.8 yes M 1 72 194 58 48 141.3 7.8 7.05 1.13 0 F 0 52 197 78 83.9 124.8 6.1 6.76 3.47 no F 1 41 189 112 56.6 98.9 9.0 5.88 2.55 yes F 0 25 186 100 58.8 111.3 7.0 7.52 2.97 yes M 1 53 169 78 105.6 108.9 7.4 0.18 1.51 yes M 0 79 160 94 65.4 107.9 5.0 5.56 2.12 0 M 0 73 151 62 67.2 117.9 7.3 6.83 1.51 0 F 0 33 153 103 70 140.5 7.7 8.51 3.48 no F 0 45 159 85 74.7 132.6 7.3 1.75 1.26 0 F 0 <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"./src/fitness_dataset.csv\")\n\ndf[\"sleep_hours\"] = df[\"sleep_hours\"].fillna(df[\"sleep_hours\"].median())\n\ndf[\"smokes\"] = (\n    df[\"smokes\"].astype(str).str.strip().str.lower()\n      .map({\"yes\": 1, \"no\": 0, \"1\": 1, \"0\": 0})\n).astype(int)\n\ndf[\"gender\"] = df[\"gender\"].replace({\"F\": 0, \"M\": 1}).astype(int)\n\nh_m = pd.to_numeric(df[\"height_cm\"], errors=\"coerce\") / 100.0\nbmi = pd.to_numeric(df[\"weight_kg\"], errors=\"coerce\") / (h_m**2)\ndf[\"bmi\"] = bmi.replace([float(\"inf\"), float(\"-inf\")], pd.NA).fillna(bmi.median())\n\nprint(df.sample(n=15).to_markdown(index=False))\n</code></pre> age height_cm weight_kg heart_rate blood_pressure sleep_hours nutrition_quality activity_index smokes gender is_fit bmi 53 169 78 105.6 108.9 7.4 0.18 1.51 1 1 0 27.31 75 153 67 85 111.9 7.9 9.51 2.11 0 1 1 28.6215 37 181 78 71.8 152.7 8.2 8.77 3.87 1 0 0 23.8088 45 179 71 68.2 115.8 7.1 3.11 3.18 0 0 0 22.1591 55 167 57 74.2 90 8.5 4.12 2.01 1 1 0 20.4382 22 184 63 76 116.1 8.2 6.74 3.59 0 0 1 18.6082 24 160 82 68.4 132.8 4.7 1.91 3.29 1 1 0 32.0312 18 167 59 84.7 135.7 8.8 1.43 2.21 0 0 0 21.1553 72 152 91 79.5 148.2 8 5.37 4 0 1 0 39.3871 34 177 96 60 128.9 7.2 6.85 3.4 0 0 1 30.6425 63 155 68 68.6 137.8 5.7 3 4.64 0 0 1 28.3039 48 197 61 81.4 121.9 5.2 0.44 1.19 0 0 0 15.718 65 177 115 80.5 117.6 6.4 5.21 3.61 1 1 0 36.7072 22 178 92 90.2 133.2 6.8 4.53 1.06 1 0 1 29.0367 29 160 84 58.9 131.5 6 3.89 1.11 0 0 0 32.8125"},{"location":"Exercicios/random_forest/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>Os dados foram divididos em treino (80%) e teste (20%) com o par\u00e2metro random_state=42 para garantir reprodutibilidade e stratify=y para manter a propor\u00e7\u00e3o entre as classes is_fit.</p> <p>Como a Random Forest \u00e9 composta por \u00e1rvores de decis\u00e3o, n\u00e3o h\u00e1 necessidade de padroniza\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas, por\u00e9m a mesma estrutura de features foi mantida para compara\u00e7\u00e3o com os demais modelos.</p> C\u00f3digo de divis\u00e3o <p>Shape X: (2000, 9) Propor\u00e7\u00e3o 'is_fit'=1: 0.3995 </p>"},{"location":"Exercicios/random_forest/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"<p>O modelo foi configurado com 300 \u00e1rvores (n_estimators=300), sele\u00e7\u00e3o aleat\u00f3ria de atributos (max_features=\"sqrt\") e profundidade ilimitada (max_depth=None), permitindo que cada \u00e1rvore se adapte ao padr\u00e3o dos dados de forma independente. O treinamento foi realizado sobre o conjunto de treino e avaliado com base na acur\u00e1cia, balanced accuracy e matriz de confus\u00e3o.</p> Matriz de Confus\u00e3oImport\u00e2ncia das Vari\u00e1veis <p>Acur\u00e1cia: 0.7600 Balanced Accuracy: 0.7375  Classification Report:                precision    recall  f1-score   support             0     0.7727    0.8500    0.8095       240            1     0.7353    0.6250    0.6757       160      accuracy                         0.7600       400    macro avg     0.7540    0.7375    0.7426       400 weighted avg     0.7578    0.7600    0.7560       400   2025-10-28T15:18:57.283151 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> 2025-10-28T15:18:58.003057 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"Exercicios/random_forest/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>A Random Forest apresentou desempenho consistente e maior estabilidade em compara\u00e7\u00e3o com modelos individuais de \u00e1rvore ou com o KNN. A matriz de confus\u00e3o mostrou uma redu\u00e7\u00e3o significativa nos erros de classifica\u00e7\u00e3o, e o valor de Balanced Accuracy indicou boa capacidade de generaliza\u00e7\u00e3o entre as classes.</p> <p>A an\u00e1lise da import\u00e2ncia das vari\u00e1veis revelou que os fatores mais determinantes para o modelo s\u00e3o:</p> <ul> <li>activity_index</li> <li>nutrition_quality</li> <li>bmi</li> <li>heart_rate</li> </ul> <p>Essas vari\u00e1veis refletem, respectivamente, o n\u00edvel de atividade f\u00edsica, a qualidade da alimenta\u00e7\u00e3o e os indicadores fisiol\u00f3gicos de sa\u00fade.</p>"},{"location":"Exercicios/random_forest/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O uso da Random Forest no dataset de fitness demonstrou excelente equil\u00edbrio entre desempenho e interpretabilidade. O modelo foi capaz de identificar padr\u00f5es consistentes que diferenciam indiv\u00edduos \u201cfit\u201d e \u201cn\u00e3o fit\u201d, destacando-se pela robustez e pela redu\u00e7\u00e3o de sobreajuste em rela\u00e7\u00e3o \u00e0 \u00e1rvore de decis\u00e3o simples.</p> <p>A an\u00e1lise confirma que h\u00e1bitos e par\u00e2metros fisiol\u00f3gicos \u2014 especialmente atividade f\u00edsica, nutri\u00e7\u00e3o e \u00edndice de massa corporal \u2014 s\u00e3o fatores-chave para a previs\u00e3o da condi\u00e7\u00e3o f\u00edsica. Como pr\u00f3ximos passos, recomenda-se explorar a otimiza\u00e7\u00e3o de hiperpar\u00e2metros (max_depth, min_samples_leaf, n_estimators) e realizar valida\u00e7\u00e3o cruzada para refinar ainda mais a performance do modelo.</p>"},{"location":"projetos/projeto1/main/","title":"Projeto 1","text":""},{"location":"projetos/projeto1/main/#grupo-3-os-goats-do-si","title":"Grupo 3 / Os Goats do SI","text":"<ol> <li>Jos\u00e9 Longo Neto</li> <li>Pedro Almeida Maricate</li> <li>Martim Ponzio</li> <li>Pablo Dimitrof</li> <li>Enzo Malagoli</li> <li>Eduardo Gul</li> </ol>"},{"location":"projetos/projeto1/main/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>O objetivo deste projeto \u00e9 aplicar tr\u00eas algoritmos de Machine Learning \u2014 \u00c1rvore de Decis\u00e3o, K-Nearest Neighbors (KNN) e K-Means (Clustering) \u2014 sobre a base de dados do kagle. A base cont\u00e9m aproximadamente 130 mil registros de vinhos, com informa\u00e7\u00f5es como pa\u00eds de origem, pontua\u00e7\u00e3o atribu\u00edda por especialistas, pre\u00e7o, tipo de uva, regi\u00e3o produtora e descri\u00e7\u00e3o sensorial.</p> <p>A proposta \u00e9 explorar o uso de algoritmos de aprendizado supervisionado e n\u00e3o supervisionado para compreender padr\u00f5es entre as vari\u00e1veis e identificar poss\u00edveis rela\u00e7\u00f5es entre caracter\u00edsticas como origem, variedade e pontua\u00e7\u00e3o dos vinhos.</p> <p>O roteiro segue a mesma estrutura aplicada em outros projetos da disciplina, dividindo o processo em etapas sequenciais e documentadas:</p> <ul> <li>Explora\u00e7\u00e3o dos Dados (EDA): an\u00e1lise geral das vari\u00e1veis, distribui\u00e7\u00e3o de valores e identifica\u00e7\u00e3o de poss\u00edveis inconsist\u00eancias;  </li> <li>Pr\u00e9-processamento: limpeza, padroniza\u00e7\u00e3o e codifica\u00e7\u00e3o de dados categ\u00f3ricos;  </li> <li>Divis\u00e3o dos Dados: separa\u00e7\u00e3o em conjuntos de treino e teste, quando houver vari\u00e1vel-alvo definida;  </li> <li>Treinamento e Avalia\u00e7\u00e3o: aplica\u00e7\u00e3o e compara\u00e7\u00e3o dos modelos supervisionados (\u00c1rvore de Decis\u00e3o e KNN);  </li> <li>Modelagem N\u00e3o Supervisionada: uso do K-Means para identificar agrupamentos entre os vinhos sem utilizar o r\u00f3tulo de pontua\u00e7\u00e3o;  </li> <li>Relat\u00f3rio Final e Compara\u00e7\u00e3o: discuss\u00e3o sobre os resultados obtidos e limita\u00e7\u00f5es de cada abordagem.</li> </ul> <p>Observa\u00e7\u00e3o: O dataset n\u00e3o possui uma coluna explicitamente bin\u00e1ria de qualidade, mas cont\u00e9m a vari\u00e1vel <code>points</code>, que representa a nota do vinho atribu\u00edda por avaliadores. Para fins de classifica\u00e7\u00e3o, esta vari\u00e1vel ser\u00e1 transformada em uma vari\u00e1vel-alvo derivada, categorizando os vinhos conforme sua pontua\u00e7\u00e3o (por exemplo, alta pontua\u00e7\u00e3o \u2265 90). Assim, os modelos supervisionados trabalhar\u00e3o com essa classifica\u00e7\u00e3o, enquanto o K-Means ser\u00e1 utilizado para detectar padr\u00f5es de agrupamento sem r\u00f3tulos.</p>"},{"location":"projetos/projeto1/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>A etapa de Explora\u00e7\u00e3o dos Dados (EDA) tem como objetivo compreender a estrutura, o conte\u00fado e o significado das vari\u00e1veis presentes na base <code>wine.csv</code>. Essa an\u00e1lise inicial permite identificar padr\u00f5es, outliers, distribui\u00e7\u00f5es e poss\u00edveis problemas de qualidade dos dados, como valores ausentes ou inconsist\u00eancias. As visualiza\u00e7\u00f5es e descri\u00e7\u00f5es abaixo ajudam a construir uma vis\u00e3o geral do conjunto e a orientar as etapas seguintes de pr\u00e9-processamento e modelagem.</p> countrydesignationpointspriceprovinceregion_1region_2taster_namevarietywinery <p>A coluna country indica o pa\u00eds de origem do vinho. Essa vari\u00e1vel \u00e9 importante para observar a distribui\u00e7\u00e3o geogr\u00e1fica dos registros e entender a representatividade de cada pa\u00eds no conjunto.</p> 2025-10-28T15:18:58.819361 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>A coluna designation informa a denomina\u00e7\u00e3o ou nome espec\u00edfico do vinho, dentro da vin\u00edcola. \u00c9 uma vari\u00e1vel categ\u00f3rica de alta cardinalidade (muitos valores \u00fanicos) e pode indicar edi\u00e7\u00f5es especiais ou lotes de produ\u00e7\u00e3o.</p> 2025-10-28T15:18:59.627953 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>A coluna points representa a pontua\u00e7\u00e3o do vinho atribu\u00edda por avaliadores especializados, geralmente variando entre 80 e 100 pontos. Essa vari\u00e1vel \u00e9 central no projeto, pois ser\u00e1 usada para derivar a vari\u00e1vel-alvo de qualidade que alimentar\u00e1 os modelos supervisionados.</p> 2025-10-28T15:19:00.429319 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>A coluna price indica o pre\u00e7o do vinho em d\u00f3lares. Ela \u00e9 uma vari\u00e1vel num\u00e9rica cont\u00ednua que pode apresentar assimetria devido \u00e0 presen\u00e7a de vinhos muito caros (outliers). A rela\u00e7\u00e3o entre pre\u00e7o e pontua\u00e7\u00e3o ser\u00e1 uma das an\u00e1lises mais relevantes desta etapa.</p> 2025-10-28T15:19:01.222979 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>A coluna province indica a prov\u00edncia ou regi\u00e3o produtora do vinho dentro de seu pa\u00eds. \u00c9 uma vari\u00e1vel categ\u00f3rica \u00fatil para observar a diversidade geogr\u00e1fica da produ\u00e7\u00e3o.</p> 2025-10-28T15:19:02.006819 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>A coluna region_1 representa uma sub-regi\u00e3o produtora (como \u201cNapa Valley\u201d ou \u201cBordeaux\u201d). Pode ser usada para an\u00e1lises mais detalhadas de terroir e diferencia\u00e7\u00e3o regional.</p> 2025-10-28T15:19:02.801543 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>A coluna region_2 fornece informa\u00e7\u00f5es complementares sobre uma segunda subdivis\u00e3o geogr\u00e1fica, quando dispon\u00edvel. Nem todos os registros possuem este campo preenchido, portanto ele pode apresentar alta taxa de valores ausentes.</p> 2025-10-28T15:19:03.589439 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>A coluna taster_name cont\u00e9m o nome do avaliador respons\u00e1vel pela nota e descri\u00e7\u00e3o do vinho. Ela permite explorar a distribui\u00e7\u00e3o de avalia\u00e7\u00f5es entre diferentes especialistas e identificar potenciais vieses.</p> 2025-10-28T15:19:04.393425 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>A coluna variety indica o tipo de uva utilizada na produ\u00e7\u00e3o (por exemplo: Pinot Noir, Chardonnay, Riesling). \u00c9 uma das vari\u00e1veis mais importantes do conjunto, pois reflete o perfil sensorial e o tipo do vinho.</p> 2025-10-28T15:19:05.200550 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>A coluna winery identifica a vin\u00edcola respons\u00e1vel pela produ\u00e7\u00e3o. \u00c9 uma vari\u00e1vel categ\u00f3rica de alta cardinalidade e pode ser explorada futuramente em an\u00e1lises de desempenho m\u00e9dio por produtor.</p> 2025-10-28T15:19:05.975190 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/"},{"location":"projetos/projeto1/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Ap\u00f3s a explora\u00e7\u00e3o inicial, aplicamos um conjunto de procedimentos para preparar a base <code>wine.csv</code> para modelagem:</p> <ul> <li>Remo\u00e7\u00e3o de colunas irrelevantes: descartamos campos sem utilidade direta para o modelo ou que ser\u00e3o usados apenas como metadados na documenta\u00e7\u00e3o (ex.: <code>Unnamed: 0</code>, <code>title</code>, <code>description</code>, <code>taster_twitter_handle</code>).  </li> <li>Convers\u00e3o e limpeza de tipos: garantimos que <code>price</code> e <code>points</code> estejam em formato num\u00e9rico; tratamos valores ausentes com imputa\u00e7\u00f5es simples (mediana para num\u00e9ricas; r\u00f3tulo <code>\"Unknown\"</code> para categ\u00f3ricas).  </li> <li>Cria\u00e7\u00e3o do alvo (quando aplic\u00e1vel): a partir de <code>points</code>, derivamos a vari\u00e1vel <code>quality_high</code> (1 se <code>points \u2265 90</code>; 0 caso contr\u00e1rio). Para evitar vazamento de informa\u00e7\u00e3o, <code>points</code> n\u00e3o ser\u00e1 usada como feature nos modelos supervisionados.  </li> <li>Codifica\u00e7\u00e3o de categ\u00f3ricas: para esta vers\u00e3o \u201cbase preparada\u201d usada na documenta\u00e7\u00e3o, aplicamos Label Encoding coluna a coluna (adequado para \u00e1rvore; nas se\u00e7\u00f5es de treino do KNN/K-Means faremos scaling e codifica\u00e7\u00f5es apropriadas nos pipelines).  </li> <li>Entrega de uma vis\u00e3o pronta para modelagem: apresentamos uma amostra da base j\u00e1 limpa e codificada, com <code>quality_high</code> dispon\u00edvel para as etapas supervisionadas e os demais campos prontos para uso em pipelines.</li> </ul> Base preparadacodeBase Original <p>Dimens\u00e3o (ap\u00f3s pr\u00e9-processamento): 129971 linhas x 10 colunas</p> country designation price province region_1 region_2 taster_name variety winery quality_high 2 35112 5 24 1027 15 8 125 952 0 15 29390 12 309 377 15 15 492 2718 0 37 12139 9 262 909 15 12 656 7019 0 40 23298 29 51 799 1 18 80 11074 0 40 37256 40 51 36 15 18 440 8338 0 40 35112 22 51 1013 0 7 125 10956 1 40 13155 33 268 1218 17 14 440 7730 1 22 30032 35 197 448 15 9 125 9739 0 40 35112 10 51 185 1 18 80 5345 0 15 7395 21 299 366 15 15 492 6439 1 40 37134 38 51 964 1 11 560 5574 0 15 29438 14 195 977 15 15 137 2639 0 15 7424 18 195 1210 15 15 137 3338 1 40 35112 20 51 911 12 18 703 11688 0 31 29965 19 7 1094 15 15 450 2411 1 22 5095 25 341 161 15 9 2 11693 0 40 9886 20 51 157 0 18 691 6891 0 17 10175 18 232 1094 15 1 479 1277 0 22 36799 20 341 855 15 18 459 586 0 40 8376 48 412 872 3 16 362 10668 1 <pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\n# ===== 1) Ler base =====\ndf = pd.read_csv(\"./src/wine.csv\")\n\n# ===== 2) Remover colunas irrelevantes (se existirem) =====\ndrop_cols = [\"Unnamed: 0\", \"title\", \"description\", \"taster_twitter_handle\"]\ndf = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n\n# ===== 3) Garantir tipos num\u00e9ricos e tratar nulos =====\nif \"points\" in df.columns:\n    df[\"points\"] = pd.to_numeric(df[\"points\"], errors=\"coerce\")\nif \"price\" in df.columns:\n    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n\nnum_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\ncat_cols = df.select_dtypes(exclude=[\"number\"]).columns.tolist()\n\nfor c in num_cols:\n    med = df[c].median() if df[c].notna().any() else 0\n    df[c] = df[c].fillna(med)\n\nfor c in cat_cols:\n    df[c] = df[c].fillna(\"Unknown\")\n\n# ===== 4) Criar alvo supervisionado (se houver points) =====\nif \"points\" in df.columns:\n    df[\"quality_high\"] = (df[\"points\"] &gt;= 90).astype(int)\n\n# ===== 5) Codifica\u00e7\u00e3o simples de categ\u00f3ricas (rastre\u00e1vel) =====\ndf_ready = df.copy()\nfor c in df_ready.select_dtypes(exclude=[\"number\"]).columns:\n    le = LabelEncoder()\n    df_ready[c] = le.fit_transform(df_ready[c].astype(str))\n\n# ===== 6) Evitar vazamento: retirar 'points' das features \"base\" =====\nif \"points\" in df_ready.columns:\n    df_ready = df_ready.drop(columns=[\"points\"])\n\n# ===== 7) Mostrar SOMENTE algumas linhas para n\u00e3o poluir o markdown =====\nn_show = min(20, len(df_ready))\nprint(f\"Dimens\u00e3o (ap\u00f3s pr\u00e9-processamento): {df_ready.shape[0]} linhas x {df_ready.shape[1]} colunas\\n\")\nprint(df_ready.sample(n=n_show, random_state=42).to_markdown(index=False))\n</code></pre> <p>Dimens\u00e3o (base original): 129971 linhas x 11 colunas</p> Unnamed: 0 country designation points price province region_1 region_2 taster_name variety winery 77718 Australia nan 83 5 Australia Other South Eastern Australia nan Joe Czerwinski Chardonnay Banrock Station 67681 France R\u00e9serve 85 12 Rh\u00f4ne Valley C\u00f4tes du Rh\u00f4ne nan Roger Voss Ros\u00e9 Cellier des Dauphins 69877 Spain Estate Grown &amp; Bottled 86 9 Northern Spain Rueda nan Michael Schachner Verdejo-Viura Esperanza 46544 US Nebula 87 29 California Paso Robles Central Coast nan Cabernet Sauvignon Midnight 186 US Wiley Vineyard 88 40 California Anderson Valley nan nan Pinot Noir Harrington 73126 US nan 90 22 California Sonoma County-Monterey County-Santa Barbara County California Other Jim Gordon Chardonnay Meiomi 26800 US Five Faces 90 33 Oregon Willamette Valley Willamette Valley Paul Gregutt Pinot Noir Fullerton 80832 Italy Saten 89 35 Lombardy Franciacorta nan Kerin O\u2019Keefe Chardonnay Lantieri de Paratico 86297 US nan 84 10 California Central Coast Central Coast nan Cabernet Sauvignon Cupcake 56015 France Clos du Ch\u00e2teau 92 21 Provence C\u00f4tes de Provence nan Roger Voss Ros\u00e9 Domaine du Clos Gautier 78536 US White Hawk Vineyard 89 38 California Santa Barbara County Central Coast Matt Kettmann Syrah Deep Sea 41016 France R\u00e9serve des Vignerons 86 14 Loire Valley Saumur nan Roger Voss Chenin Blanc Cave de Saumur 81019 France Clos le Vigneau 90 18 Loire Valley Vouvray nan Roger Voss Chenin Blanc Ch\u00e2teau Gaudrelle 129762 US nan 87 20 California Russian River Valley Sonoma nan Zinfandel Novy 34634 Portugal Santos da Casa Reserva 91 19 Alentejano nan nan Roger Voss Portuguese Red Casca Wines 20284 Italy Caleno Oro 88 nan Southern Italy Campania nan Kerin O\u2019Keefe Aglianico Nugnes 111397 US Dessert Wine 86 20 California California California Other nan White Blend Elkhorn Peak 26153 Germany Dom Off-Dry 89 18 Mosel nan nan Anna Lee C. Iijima Riesling Bisch\u00f6fliche Weing\u00fcter Trier 110148 Italy Vriccio 86 20 Southern Italy Puglia nan nan Primitivo Antica Enotria 125453 US Crazy Mary 93 48 Washington Red Mountain Columbia Valley Sean P. Sullivan Mourv\u00e8dre Mark Ryan"},{"location":"projetos/projeto1/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>Com a base pr\u00e9-processada, realizou-se a divis\u00e3o entre conjuntos de treinamento e teste. O objetivo dessa etapa \u00e9 garantir que o modelo seja avaliado em dados que ele nunca viu durante o treinamento, permitindo uma medida mais confi\u00e1vel de sua capacidade de generaliza\u00e7\u00e3o.  </p> <p>Foi utilizada a fun\u00e7\u00e3o <code>train_test_split</code> da biblioteca scikit-learn, com os seguintes crit\u00e9rios: - 70% dos dados destinados ao treinamento, para que o modelo aprenda os padr\u00f5es da base; - 30% dos dados destinados ao teste, para avaliar o desempenho em novos exemplos; - Estratifica\u00e7\u00e3o pelo alvo (<code>quality_high</code>), garantindo que a propor\u00e7\u00e3o entre classes seja mantida em ambos os conjuntos; - Random State fixado, assegurando reprodutibilidade na divis\u00e3o.  </p> <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# ===== 1) Ler base =====\ndf = pd.read_csv(\"./src/wine.csv\")\n\n# ===== 2) Remover colunas irrelevantes (se existirem) =====\ndrop_cols = [\"Unnamed: 0\", \"title\", \"description\", \"taster_twitter_handle\"]\ndf = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n\n# ===== 3) Convers\u00f5es de tipo essenciais =====\nif \"points\" in df.columns:\n    df[\"points\"] = pd.to_numeric(df[\"points\"], errors=\"coerce\")\nif \"price\" in df.columns:\n    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n\n# ===== 4) Criar alvo supervisionado a partir de 'points' =====\n# quality_high = 1 (&gt;= 90), 0 (&lt; 90)\n# Linhas sem 'points' n\u00e3o ajudam na classifica\u00e7\u00e3o \u2014 removemos\ndf = df[df[\"points\"].notna()].copy()\ndf[\"quality_high\"] = (df[\"points\"] &gt;= 90).astype(int)\n\n# ===== 5) Codificar vari\u00e1veis categ\u00f3ricas (LabelEncoder simples) =====\ncat_cols = [\n    col for col in [\"country\", \"province\", \"region_1\", \"region_2\",\n                    \"taster_name\", \"designation\", \"variety\", \"winery\"]\n    if col in df.columns\n]\n\nfor c in cat_cols:\n    le = LabelEncoder()\n    df[c] = df[c].fillna(\"Unknown\").astype(str)\n    df[c] = le.fit_transform(df[c])\n\n# ===== 6) Definir X (features) e y (alvo), evitando vazamento de 'points' =====\nfeature_cols = []\nfeature_cols += [c for c in cat_cols]              # categ\u00f3ricas codificadas\nif \"price\" in df.columns:\n    feature_cols.append(\"price\")                   # num\u00e9rica \u00fatil\n# N\u00c3O usar 'points' como feature (origem do alvo)\nX = df[feature_cols].copy()\ny = df[\"quality_high\"].copy()\n\n# ===== 7) Divis\u00e3o treino/teste com estratifica\u00e7\u00e3o =====\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.30,\n    random_state=27,\n    stratify=y\n)\n</code></pre>"},{"location":"projetos/projeto1/main/#treinamento-do-modelo-arvore-de-decisao","title":"Treinamento do Modelo \u2014 \u00c1rvore de Decis\u00e3o","text":"<p>Nesta etapa treinamos um DecisionTreeClassifier utilizando a base pr\u00e9-processada. Mantemos a mesma prepara\u00e7\u00e3o usada na divis\u00e3o (remo\u00e7\u00e3o de colunas irrelevantes, cria\u00e7\u00e3o de <code>quality_high</code> a partir de <code>points</code>, codifica\u00e7\u00e3o das categ\u00f3ricas) e realizamos o ajuste do modelo com 70/30 de treino/teste e <code>random_state=27</code>.</p> Modelo da \u00c1rvorecode <p>Precis\u00e3o da Valida\u00e7\u00e3o: 0.75 Import\u00e2ncia das Features:  Feature Import\u00e2ncia price 0.343989 winery 0.205696 designation 0.169186 variety 0.091451 region_1 0.082287 taster_name 0.034639 province 0.034284 country 0.020755 region_2 0.017713 2025-10-28T15:19:09.320593 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\n# ===================== Ler base =====================\ndf = pd.read_csv(\"./src/wine.csv\")\n\n# ===================== Excluir colunas n\u00e3o desejadas =====================\n# (mesma ideia do seu script antigo: tirar campos irrelevantes/verbosos)\ndrop_cols = [\"Unnamed: 0\", \"title\", \"description\", \"taster_twitter_handle\"]\ndf = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n\n# ===================== Convers\u00f5es b\u00e1sicas =====================\n# 'points' ser\u00e1 usada para criar o alvo; por isso N\u00c3O entra em X\ndf[\"points\"] = pd.to_numeric(df[\"points\"], errors=\"coerce\")\n\n# price pode ter nulos; converte e imputa mediana\nif \"price\" in df.columns:\n    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n    if df[\"price\"].isna().any():\n        df[\"price\"] = df[\"price\"].fillna(df[\"price\"].median())\n\n# manter somente linhas com 'points' (necess\u00e1rio para o alvo)\ndf = df[df[\"points\"].notna()].copy()\n\n# ===================== Criar alvo supervisionado =====================\n# quality_high = 1 (&gt;= 90), 0 (&lt; 90)\ndf[\"quality_high\"] = (df[\"points\"] &gt;= 90).astype(int)\n\n# ===================== Label encoding das categ\u00f3ricas =====================\n# (seguindo o esp\u00edrito do seu antigo: LabelEncoder direto nas colunas de texto)\ncat_cols = [c for c in [\"country\", \"province\", \"region_1\", \"region_2\",\n                        \"taster_name\", \"designation\", \"variety\", \"winery\"]\n            if c in df.columns]\n\nfor c in cat_cols:\n    le = LabelEncoder()\n    df[c] = df[c].fillna(\"Unknown\").astype(str)\n    df[c] = le.fit_transform(df[c])\n\n# ===================== Defini\u00e7\u00e3o de features (X) e alvo (y) =====================\n# Evitar vazamento: NUNCA usar 'points' em X, pois dela deriva o alvo\nfeature_cols = []\nfeature_cols += cat_cols\nif \"price\" in df.columns:\n    feature_cols.append(\"price\")\n\nx = df[feature_cols].copy()\ny = df[\"quality_high\"].copy()\n\n# ===================== Divis\u00e3o treino/teste =====================\nx_train, x_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.3, random_state=27, stratify=y\n)\n\n# ===================== Criar e treinar o modelo de \u00e1rvore de decis\u00e3o =====================\nclassifier = tree.DecisionTreeClassifier(random_state=27)\nclassifier.fit(x_train, y_train)\n\n# ===================== Avaliar o modelo =====================\ny_pred = classifier.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Precis\u00e3o da Valida\u00e7\u00e3o: {accuracy:.2f}\")\n\n# Import\u00e2ncia das features\nfeature_importance = pd.DataFrame({\n    'Feature': classifier.feature_names_in_,\n    'Import\u00e2ncia': classifier.feature_importances_\n}).sort_values(by='Import\u00e2ncia', ascending=False)\n\nprint(\"&lt;br&gt;Import\u00e2ncia das Features:\")\nprint(feature_importance.to_html(index=False))\n\n# ===================== Plot da \u00e1rvore (at\u00e9 profundidade 5, como no seu padr\u00e3o) =====================\nplt.figure(figsize=(20, 10))\ntry:\n    tree.plot_tree(classifier, max_depth=5, fontsize=10, feature_names=classifier.feature_names_in_)\nexcept Exception:\n    tree.plot_tree(classifier, max_depth=5, fontsize=10)\n\n# Para imprimir na p\u00e1gina HTML (MkDocs)\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"projetos/projeto1/main/#avaliacao-do-modelo-arvore-de-decisao","title":"Avalia\u00e7\u00e3o do Modelo \u2014 \u00c1rvore de Decis\u00e3o","text":"<p>Ap\u00f3s o treinamento, a \u00e1rvore foi avaliada no conjunto de teste (30%), garantindo que as m\u00e9tricas reflitam a capacidade de generaliza\u00e7\u00e3o do modelo. As sa\u00eddas principais consideradas s\u00e3o:</p> <ul> <li>Acur\u00e1cia (teste): propor\u00e7\u00e3o de acertos sobre o total de amostras de teste;  </li> <li>Matriz de Confus\u00e3o: distribui\u00e7\u00e3o de acertos/erros por classe (0 = qualidade comum, 1 = alta qualidade), \u00fatil para inspecionar erros assim\u00e9tricos;  </li> <li>Classification Report: m\u00e9tricas por classe (precision, recall e F1), evidenciando se o modelo est\u00e1 sacrificando uma classe em detrimento da outra;  </li> <li>Import\u00e2ncia das Features: ranking de vari\u00e1veis mais influentes na decis\u00e3o (ex.: <code>variety</code>, <code>province/country</code>, <code>price</code>), auxiliando na interpreta\u00e7\u00e3o.</li> </ul>"},{"location":"projetos/projeto1/main/#observacoes-e-interpretacao","title":"Observa\u00e7\u00f5es e interpreta\u00e7\u00e3o","text":"<ul> <li>Desbalanceamento: \u00e9 comum a classe \u201calta qualidade\u201d (\u2265 90 pontos) ser minorit\u00e1ria, o que pode reduzir o recall dessa classe mesmo com acur\u00e1cia global razo\u00e1vel.  </li> <li>Overfitting: \u00e1rvores muito profundas tendem a memorizar o treino. Se a diferen\u00e7a entre desempenho de treino e teste for alta, recomenda-se restringir <code>max_depth</code>, <code>min_samples_leaf</code> e/ou <code>min_samples_split</code>.  </li> <li>Vari\u00e1veis proxy: atributos geogr\u00e1ficos (<code>country</code>, <code>province</code>, <code>region_*</code>) e <code>variety</code> podem capturar padr\u00f5es de estilo/qualidade; <code>price</code> costuma aparecer relevante, mas aten\u00e7\u00e3o a correla\u00e7\u00f5es esp\u00farias e vi\u00e9s de sele\u00e7\u00e3o.  </li> <li>Sem vazamento: a vari\u00e1vel <code>points</code> foi usada apenas para gerar o alvo (<code>quality_high</code>) e n\u00e3o entrou como feature nas previs\u00f5es.</li> </ul>"},{"location":"projetos/projeto1/main/#treinamento-do-modelo-knn","title":"Treinamento do Modelo - KNN","text":"<p>Nesta se\u00e7\u00e3o foi implementado o algoritmo KNN de forma manual, a partir do zero, para consolidar o entendimento do funcionamento do m\u00e9todo. A implementa\u00e7\u00e3o considera a dist\u00e2ncia euclidiana entre os pontos, identifica os vizinhos mais pr\u00f3ximos e atribui a classe com maior frequ\u00eancia. Esse exerc\u00edcio \u00e9 importante para compreender a l\u00f3gica por tr\u00e1s do KNN antes de utilizar bibliotecas prontas.</p> ModeloC\u00f3digo <p>Acur\u00e1cia (KNN manual, k=5): 0.716 Tamanho treino/teste: 3500 / 1500 </p> <p>Acur\u00e1cia (KNN manual, k=5): 0.716 Tamanho treino/teste: 3500 / 1500 </p>"},{"location":"projetos/projeto1/main/#usando-scikit-learn","title":"Usando Scikit-Learn","text":"<p>Aqui repetimos a prepara\u00e7\u00e3o e treinamos o KNeighborsClassifier do scikit-learn. Para fins de visualiza\u00e7\u00e3o, usamos PCA (2D) apenas para projetar os dados e exibir a fronteira de decis\u00e3o do KNN no plano, junto de um gr\u00e1fico de dispers\u00e3o dos pontos de treino.</p> ResultadoC\u00f3digo <p>Acur\u00e1cia (KNN sklearn c/ PCA 2D, k=5): 0.709  2025-10-28T15:19:47.446237 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import numpy as np\nimport pandas as pd\n\nimport matplotlib\nmatplotlib.use(\"Agg\")  # backend headless para rodar no mkdocs\nimport matplotlib.pyplot as plt\n\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\n# 1) Carregar base\ndf = pd.read_csv(\"./src/wine.csv\")\n\n# 2) Limpeza b\u00e1sica e alvo\ndrop_cols = [\"Unnamed: 0\", \"title\", \"description\", \"taster_twitter_handle\"]\ndf = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n\ndf[\"points\"] = pd.to_numeric(df.get(\"points\"), errors=\"coerce\")\nif \"price\" in df.columns:\n    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n\ndf = df[df[\"points\"].notna()].copy()\ndf[\"quality_high\"] = (df[\"points\"] &gt;= 90).astype(int)\n\n# 3) Amostragem estratificada cedo (antes de dummies) para visualiza\u00e7\u00e3o\nMAX_VIS = 4000\nif len(df) &gt; MAX_VIS:\n    frac = MAX_VIS / len(df)\n    df = (\n        df.groupby(\"quality_high\", group_keys=False)\n          .apply(lambda g: g.sample(frac=frac, random_state=42))\n          .reset_index(drop=True)\n    )\n\ny = df[\"quality_high\"].values\n\n# 4) Features (evitar cardinalidade absurda)\nnum_cols = [c for c in [\"price\"] if c in df.columns]\ncat_cols = [c for c in [\"country\", \"province\", \"region_1\", \"variety\"] if c in df.columns]\n\nfor c in num_cols:\n    df[c] = df[c].fillna(df[c].median())\nfor c in cat_cols:\n    df[c] = df[c].fillna(\"Unknown\").astype(str).str.strip()\n\nX_cat = pd.get_dummies(df[cat_cols], drop_first=False, dtype=int) if cat_cols else pd.DataFrame(index=df.index)\nX_num = df[num_cols].copy() if num_cols else pd.DataFrame(index=df.index)\n\nif not X_num.empty:\n    scaler = StandardScaler()\n    X_num[num_cols] = scaler.fit_transform(X_num[num_cols])\n\nX = pd.concat([X_num, X_cat], axis=1).values\n\n# 5) Split (70/30), manter consist\u00eancia\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.30, random_state=27, stratify=y\n)\n\n# 6) PCA (2D) apenas para visualiza\u00e7\u00e3o/fronteira\npca = PCA(n_components=2, random_state=27)\nX_train_2d = pca.fit_transform(X_train)\nX_test_2d  = pca.transform(X_test)\n\n# 7) KNN no espa\u00e7o 2D projetado\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train_2d, y_train)\npred = knn.predict(X_test_2d)\nacc = accuracy_score(y_test, pred)\nprint(f\"Acur\u00e1cia (KNN sklearn c/ PCA 2D, k=5): {acc:.3f}\")\n\n# 8) Fronteira de decis\u00e3o em 2D (grid menos denso pra n\u00e3o travar)\nplt.figure(figsize=(8, 6))\nh = 0.25\n\nx_min, x_max = X_train_2d[:, 0].min() - 1, X_train_2d[:, 0].max() + 1\ny_min, y_max = X_train_2d[:, 1].min() - 1, X_train_2d[:, 1].max() + 1\n\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\nplt.contourf(xx, yy, Z, alpha=0.3)\nplt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train, s=16, edgecolors=\"k\", alpha=0.8)\n\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.title(\"KNN \u2014 Fronteira de decis\u00e3o (PCA 2D)\")\nplt.tight_layout()\n\nbuf = StringIO()\nplt.savefig(buf, format=\"svg\", transparent=True)\nprint(buf.getvalue())\nplt.close()\n</code></pre>"},{"location":"projetos/projeto1/main/#avaliacao-do-modelo-knn","title":"Avalia\u00e7\u00e3o do Modelo - KNN","text":"<p>Ap\u00f3s o treinamento, avaliamos a acur\u00e1cia em teste nas duas abordagens (manual e com scikit-learn). Como o alvo \u00e9 quality_high (derivado de points), o desempenho pode ser afetado por desbalanceamento (vinhos com nota \u2265 90 tendem a ser minoria). Al\u00e9m disso, o KNN \u00e9 sens\u00edvel \u00e0 escala e \u00e0 escolha de k, o que pode gerar varia\u00e7\u00e3o de resultados. A visualiza\u00e7\u00e3o em PCA 2D tende a mostrar sobreposi\u00e7\u00e3o entre classes, refor\u00e7ando a dificuldade de separa\u00e7\u00e3o perfeita nesse dom\u00ednio.</p>"},{"location":"projetos/projeto1/main/#treinamento-do-modelo-k-means","title":"Treinamento do Modelo - K-Means","text":"<p>O modelo K-Means foi treinado com 3 clusters como refer\u00eancia pedag\u00f3gica para segmentar perfis de vinhos (ex.: baixa/m\u00e9dia/alta qualidade percebida). Ap\u00f3s o pr\u00e9-processamento (padroniza\u00e7\u00e3o de vari\u00e1veis num\u00e9ricas e one-hot para categ\u00f3ricas selecionadas), aplicamos o K-Means e projetamos os dados em PCA (2D) para visualiza\u00e7\u00e3o dos grupos e de seus centr\u00f3ides.</p> ModeloC\u00f3digo <p> </p> <pre><code>import base64\nfrom io import BytesIO\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib\nmatplotlib.use(\"Agg\")  # backend headless p/ rodar no mkdocs\nimport matplotlib.pyplot as plt\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# 1) Carregar base\ndf = pd.read_csv(\"./src/wine.csv\")\n\n# 2) Remover campos verbosos/irrelevantes (se existirem)\ndrop_cols = [\"Unnamed: 0\", \"title\", \"description\", \"taster_twitter_handle\"]\ndf = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n\n# 3) Convers\u00f5es e imputa\u00e7\u00f5es m\u00ednimas\ndf[\"points\"] = pd.to_numeric(df.get(\"points\"), errors=\"coerce\")\nif \"price\" in df.columns:\n    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n    df[\"price\"] = df[\"price\"].fillna(df[\"price\"].median())\n\n# 4) AMOSTRAGEM cedo (para n\u00e3o pesar no build)\nMAX_ROWS = 5000\nif len(df) &gt; MAX_ROWS:\n    df = df.sample(MAX_ROWS, random_state=27).reset_index(drop=True)\n\n# 5) Sele\u00e7\u00e3o de features (evitar cardinalidade extrema)\nnum_cols = [c for c in [\"price\"] if c in df.columns]\ncat_cols = [c for c in [\"country\", \"province\", \"region_1\", \"variety\"] if c in df.columns]  # sem taster_name\n\nfor c in cat_cols:\n    df[c] = df[c].fillna(\"Unknown\").astype(str).str.strip()\n\nX_cat = pd.get_dummies(df[cat_cols], drop_first=False, dtype=int) if cat_cols else pd.DataFrame(index=df.index)\nX_num = df[num_cols].copy() if num_cols else pd.DataFrame(index=df.index)\n\nif not X_num.empty:\n    scaler = StandardScaler()\n    X_num[num_cols] = scaler.fit_transform(X_num[num_cols])\n\nX = pd.concat([X_num, X_cat], axis=1).values\n\n# 6) PCA 2D para visualiza\u00e7\u00e3o\npca = PCA(n_components=2, random_state=27)\nX_pca = pca.fit_transform(X)\n\n# 7) K-Means no espa\u00e7o 2D (k=3)\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", max_iter=300, n_init=10, random_state=27)\nlabels = kmeans.fit_predict(X_pca)\n\n# 8) Plot (matplotlib puro) e sa\u00edda em base64 (HTML &lt;img&gt;)\nplt.figure(figsize=(8, 6))\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, s=18, alpha=0.85)\nplt.scatter(\n    kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n    c=\"red\", marker=\"*\", s=200, label=\"Centr\u00f3ides\"\n)\nplt.title(\"K-Means (Wine) \u2014 PCA 2D, k=3\")\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.legend(loc=\"best\")\n\nbuf = BytesIO()\nplt.savefig(buf, format=\"png\", transparent=True, bbox_inches=\"tight\")\nplt.close()\nbuf.seek(0)\nimg_b64 = base64.b64encode(buf.read()).decode(\"utf-8\")\nprint(f'&lt;img src=\"data:image/png;base64,{img_b64}\" alt=\"KMeans clustering (Wine)\"/&gt;')\n</code></pre>"},{"location":"projetos/projeto1/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Para avaliar o clustering, mapeamos os clusters para o r\u00f3tulo derivado quality_high (1 se points \u2265 90, 0 caso contr\u00e1rio) por voto majorit\u00e1rio em cada grupo. Assim, obtemos m\u00e9tricas de classifica\u00e7\u00e3o mesmo em um cen\u00e1rio originalmente n\u00e3o supervisionado, incluindo acur\u00e1cia e matriz de confus\u00e3o.</p> ResultadoC\u00f3digo <p>Acur\u00e1cia (mapeamento por voto, treino): 62.90% Matriz de Confus\u00e3o (treino):  Classe Pred 0 Classe Pred 1 Classe Real 0 2614 1 Classe Real 1 1557 28 </p> <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# 1) Carregar base\ndf = pd.read_csv(\"./src/wine.csv\")\n\n# 2) Limpeza e alvo derivado\ndrop_cols = [\"Unnamed: 0\", \"title\", \"description\", \"taster_twitter_handle\"]\ndf = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n\ndf[\"points\"] = pd.to_numeric(df.get(\"points\"), errors=\"coerce\")\ndf = df[df[\"points\"].notna()].copy()  # necess\u00e1rio para quality_high\n\nif \"price\" in df.columns:\n    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n    df[\"price\"] = df[\"price\"].fillna(df[\"price\"].median())\n\ndf[\"quality_high\"] = (df[\"points\"] &gt;= 90).astype(int)\ny = df[\"quality_high\"].values\n\n# 3) AMOSTRAGEM estratificada cedo (para n\u00e3o pesar no build)\nMAX_ROWS = 6000\nif len(df) &gt; MAX_ROWS:\n    frac = MAX_ROWS / len(df)\n    df = (\n        df.groupby(\"quality_high\", group_keys=False)\n          .apply(lambda g: g.sample(frac=frac, random_state=27))\n          .reset_index(drop=True)\n    )\ny = df[\"quality_high\"].values\n\n# 4) Features (evitar cardinalidade extrema)\nnum_cols = [c for c in [\"price\"] if c in df.columns]\ncat_cols = [c for c in [\"country\", \"province\", \"region_1\", \"variety\"] if c in df.columns]  # sem taster_name\n\nfor c in cat_cols:\n    df[c] = df[c].fillna(\"Unknown\").astype(str).str.strip()\n\nX_cat = pd.get_dummies(df[cat_cols], drop_first=False, dtype=int) if cat_cols else pd.DataFrame(index=df.index)\nX_num = df[num_cols].copy() if num_cols else pd.DataFrame(index=df.index)\n\nif not X_num.empty:\n    scaler = StandardScaler()\n    X_num[num_cols] = scaler.fit_transform(X_num[num_cols])\n\nX = pd.concat([X_num, X_cat], axis=1).values\n\n# 5) Split (70/30) + PCA no treino\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.30, random_state=27, stratify=y\n)\n\npca = PCA(n_components=2, random_state=27)\nX_train_pca = pca.fit_transform(X_train)\n\n# 6) K-Means em treino (k=3) e mapeamento cluster-&gt;classe por voto majorit\u00e1rio\nkmeans = KMeans(n_clusters=3, init=\"k-means++\", max_iter=300, n_init=10, random_state=27)\nlabels_train = kmeans.fit_predict(X_train_pca)\n\ncluster_map = {}\nclasses = np.unique(y_train)\nfor c in np.unique(labels_train):\n    mask = labels_train == c\n    if mask.sum() == 0:\n        cluster_map[c] = classes[0]\n        continue\n    counts = np.bincount(y_train[mask], minlength=classes.max() + 1)\n    cluster_map[c] = counts.argmax()\n\n# 7) Acur\u00e1cia e matriz de confus\u00e3o (TREINO), como no seu exemplo\ny_pred_train = np.array([cluster_map[c] for c in labels_train])\nacc = accuracy_score(y_train, y_pred_train)\ncm = confusion_matrix(y_train, y_pred_train, labels=np.sort(classes))\n\ncm_df = pd.DataFrame(\n    cm,\n    index=[f\"Classe Real {cls}\" for cls in np.sort(classes)],\n    columns=[f\"Classe Pred {cls}\" for cls in np.sort(classes)]\n)\n\nprint(f\"Acur\u00e1cia (mapeamento por voto, treino): {acc*100:.2f}%\")\nprint(\"&lt;br&gt;Matriz de Confus\u00e3o (treino):\")\nprint(cm_df.to_html(index=True))\n</code></pre>"},{"location":"projetos/projeto1/main/#conclusao-geral-do-projeto","title":"Conclus\u00e3o Geral do Projeto","text":"<p>O projeto teve como objetivo aplicar e comparar tr\u00eas abordagens cl\u00e1ssicas de Machine Learning \u2014 \u00c1rvore de Decis\u00e3o, KNN (K-Nearest Neighbors) e K-Means \u2014 sobre o dataset kagle de vinhos, que cont\u00e9m informa\u00e7\u00f5es como pa\u00eds, regi\u00e3o, variedade, provador, pre\u00e7o e pontua\u00e7\u00e3o (vari\u00e1vel <code>points</code>), entre outras. A proposta foi compreender como diferentes t\u00e9cnicas de aprendizado supervisionado e n\u00e3o supervisionado lidam com o problema de prever ou agrupar vinhos de alta qualidade (definidos como aqueles com pontua\u00e7\u00e3o \u2265 90).</p>"},{"location":"projetos/projeto1/main/#sobre-a-base-de-dados","title":"Sobre a Base de Dados","text":"<p>A base apresenta alta cardinalidade categ\u00f3rica (muitos valores distintos em colunas como <code>variety</code> e <code>region_1</code>) e distribui\u00e7\u00e3o desigual entre pa\u00edses e faixas de pontua\u00e7\u00e3o. Por esse motivo, foi necess\u00e1rio aplicar pr\u00e9-processamentos cuidadosos, como: - normaliza\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas (<code>price</code>); - one-hot encoding para vari\u00e1veis categ\u00f3ricas; - e amostragem estratificada para reduzir o custo computacional mantendo representatividade.  </p> <p>Essa estrutura favoreceu a an\u00e1lise, mas tamb\u00e9m revelou as limita\u00e7\u00f5es naturais do conjunto \u2014 com poucos atributos diretamente relacionados \u00e0 qualidade sensorial do vinho, as previs\u00f5es tendem a capturar mais o perfil geral do mercado do que a avalia\u00e7\u00e3o cr\u00edtica de especialistas.</p>"},{"location":"projetos/projeto1/main/#arvore-de-decisao","title":"\u00c1rvore de Decis\u00e3o","text":"<p>O modelo de \u00c1rvore de Decis\u00e3o apresentou uma acur\u00e1cia de 75%, sendo o melhor desempenho entre os m\u00e9todos supervisionados testados. A an\u00e1lise das import\u00e2ncias das vari\u00e1veis mostrou que: - o pre\u00e7o \u00e9 o principal preditor (forte correla\u00e7\u00e3o com a pontua\u00e7\u00e3o), - seguido por winery e designation, que representam o produtor e o r\u00f3tulo do vinho.  </p> <p>O modelo conseguiu estruturar regras compreens\u00edveis \u2014 como faixas de pre\u00e7o associadas \u00e0 qualidade \u2014, refor\u00e7ando o car\u00e1ter interpret\u00e1vel das \u00e1rvores. Ainda assim, parte do resultado pode refletir overfitting leve, j\u00e1 que a \u00e1rvore aprende padr\u00f5es muito espec\u00edficos de produtores e regi\u00f5es.</p>"},{"location":"projetos/projeto1/main/#knn-k-nearest-neighbors","title":"KNN (K-Nearest Neighbors)","text":"<p>O KNN manual alcan\u00e7ou \u224871,6% de acur\u00e1cia, enquanto a vers\u00e3o com Scikit-Learn e proje\u00e7\u00e3o via PCA (2D) obteve cerca de 70,8%. O gr\u00e1fico de fronteira de decis\u00e3o mostrou uma sobreposi\u00e7\u00e3o significativa entre classes, especialmente nas regi\u00f5es de m\u00e9dia qualidade. Isso refor\u00e7a o fato de que os atributos dispon\u00edveis n\u00e3o separam de forma n\u00edtida os vinhos de alta e baixa pontua\u00e7\u00e3o.</p> <p>Apesar disso, o KNN apresentou comportamento consistente e intuitivo: - bons resultados para amostras com padr\u00f5es similares de regi\u00e3o e variedade; - sensibilidade a escala e densidade de vizinhan\u00e7a, exigindo scaling e escolha adequada de <code>k</code>.</p>"},{"location":"projetos/projeto1/main/#k-means-clustering","title":"K-Means (Clustering)","text":"<p>O K-Means, aplicado com 3 clusters, buscou agrupar vinhos de maneira n\u00e3o supervisionada, representando diferentes perfis de qualidade. Os grupos formados mostraram tend\u00eancia de separa\u00e7\u00e3o, mas com fronteiras difusas, o que \u00e9 esperado dado que os dados n\u00e3o possuem r\u00f3tulos expl\u00edcitos de classes distintas. O mapeamento por voto majorit\u00e1rio atingiu \u224862,9% de acur\u00e1cia, com confus\u00e3o entre vinhos medianos e de alta pontua\u00e7\u00e3o.</p> <p>O resultado indica que, embora o K-Means consiga identificar padr\u00f5es estruturais (como faixas de pre\u00e7o e origem), ele n\u00e3o captura com precis\u00e3o o conceito subjetivo de \u201cqualidade\u201d \u2014 que depende de fatores sensoriais n\u00e3o representados na base.</p>"},{"location":"projetos/projeto1/main/#consideracoes-finais","title":"Considera\u00e7\u00f5es Finais","text":"<p>Comparando os modelos:</p> Modelo Tipo de Aprendizado Acur\u00e1cia Observa\u00e7\u00f5es \u00c1rvore de Decis\u00e3o Supervisionado 0.75 Melhor desempenho; interpret\u00e1vel; sens\u00edvel a overfitting KNN Supervisionado ~0.71 Bom em padr\u00f5es locais; alta sobreposi\u00e7\u00e3o entre classes K-Means N\u00e3o supervisionado ~0.63 Agrupamento coerente, mas difuso; \u00fatil para segmenta\u00e7\u00e3o explorat\u00f3ria <p>Em s\u00edntese, o projeto mostrou que: - modelos supervisionados (\u00c1rvore e KNN) se beneficiam do conhecimento pr\u00e9vio das classes e alcan\u00e7am resultados mais robustos; - o K-Means, embora menos preciso, \u00e9 \u00fatil para an\u00e1lises explorat\u00f3rias e descoberta de padr\u00f5es; - e que a qualidade do dado \u00e9 t\u00e3o ou mais determinante do que o algoritmo escolhido \u2014 atributos objetivos como pre\u00e7o e origem s\u00e3o insuficientes para explicar completamente uma vari\u00e1vel subjetiva como \u201cpontua\u00e7\u00e3o de degusta\u00e7\u00e3o\u201d.</p> <p>Assim, o estudo refor\u00e7a a import\u00e2ncia do pr\u00e9-processamento, sele\u00e7\u00e3o de vari\u00e1veis e an\u00e1lise cr\u00edtica dos resultados em qualquer projeto de Machine Learning, especialmente em dom\u00ednios complexos como o enol\u00f3gico, onde os dados quantitativos capturam apenas parte da realidade avaliada por especialistas.</p>"},{"location":"projetos/projeto1/main/#reflexao-final","title":"Reflex\u00e3o Final","text":"<p>O desenvolvimento deste projeto proporcionou uma vis\u00e3o pr\u00e1tica do ciclo completo de Machine Learning: desde a limpeza e transforma\u00e7\u00e3o de dados at\u00e9 a avalia\u00e7\u00e3o e compara\u00e7\u00e3o de modelos. Ficou evidente que compreender o contexto do problema e a natureza dos dados \u00e9 essencial para interpretar resultados e extrair conclus\u00f5es relevantes. Mais do que alcan\u00e7ar a maior acur\u00e1cia poss\u00edvel, o aprendizado principal foi entender como cada modelo oferece uma lente diferente sobre os mesmos dados, revelando tanto suas potencialidades quanto suas limita\u00e7\u00f5es.</p>"},{"location":"roteiros/roteiro1/main/","title":"Main","text":""},{"location":"roteiros/roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"roteiros/roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"roteiros/roteiro1/main/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p></p> <p>Dashboard do MAAS</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"roteiros/roteiro1/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"roteiros/roteiro1/main/#app","title":"App","text":""},{"location":"roteiros/roteiro1/main/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"roteiros/roteiro1/main/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <pre><code>architecture-beta\n    group api(cloud)[API]\n\n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n\n    db:L -- R:server \n    disk1:T -- B:server\n    disk2:T -- B:db</code></pre> <p>Mermaid</p>"},{"location":"roteiros/roteiro1/main/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"roteiros/roteiro1/main/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"roteiros/roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"roteiros/roteiro2/main/","title":"Main","text":""},{"location":"roteiros/roteiro2/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica { \n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"roteiros/roteiro2/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"roteiros/roteiro3/main/","title":"Main","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> </p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> <p></p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"roteiros/roteiro4/main/","title":"Main","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> <p></p> <p></p> <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa. </p>"},{"location":"thisdocumentation/main/","title":"Main","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}